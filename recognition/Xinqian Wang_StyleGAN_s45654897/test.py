# -*- coding: utf-8 -*-
"""StyleGANipynb_IMDB_dataset

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ESymP5t0SlXdN5NAvuzKRmyyBI3GrO4F
"""
# Commented out IPython magic to ensure Python compatibility.
from math import sqrt
import os
import random

import argparse
import random
import math

from tqdm import tqdm
import numpy as np
from PIL import Image

import torch
from torch import nn, optim
from torch.nn import functional as F
from torch.autograd import Variable, grad
from torch.utils.data import DataLoader
from torchvision import datasets, transforms, utils
from torch.utils.data import Dataset
from torch.nn import init
from torch.autograd import Function

import matplotlib.pyplot as plt
# %matplotlib inline

from model import StyledGenerator, Discriminator

@torch.no_grad()
def get_mean_style(generator, device):
    # generate 1024 codes ten times and average them
    mean_style = None

    for i in range(10):
        style = generator.mean_style(torch.randn(1024, 512).to(device))

        if mean_style is None:
            mean_style = style

        else:
            mean_style += style

    mean_style /= 10
    return mean_style

@torch.no_grad()
def sample(generator, step, mean_style, n_sample, device):
    image = generator(
        torch.randn(n_sample, 512).to(device),
        step=step,
        alpha=1,
        mean_style=mean_style,
        style_weight=0.7,
    )
    
    return image

@torch.no_grad()
def style_mixing(generator, step, mean_style, n_source, n_target, device):
    source_code = torch.randn(n_source, 512).to(device)
    target_code = torch.randn(n_target, 512).to(device)
    
    shape = 4 * 2 ** step
    alpha = 1

    images = [torch.zeros(1, 3, shape, shape).to(device) * -1]
    images_data = {}
    images_data[0] = (0,0)

    source_image = generator(
        source_code, step=step, alpha=alpha, mean_style=mean_style, style_weight=0.7
    )
    target_image = generator(
        target_code, step=step, alpha=alpha, mean_style=mean_style, style_weight=0.7
    )
    
    images.append(source_image)
    for i in range(n_source):
      images_data[i+1] = (torch.mean(source_image[i]),torch.std(source_image[i]))
    #print('end for source_image')
    images_data_length = len(images_data)
    #images_data.append()
    for i in range(n_target):
        image = generator(
            [target_code[i].unsqueeze(0).repeat(n_source, 1), source_code],
            step=step,
            alpha=alpha,
            mean_style=mean_style,
            style_weight=0.7,
            mixing_range=(0, 1),
        )

        images_data[images_data_length] = (torch.mean(target_image[i].unsqueeze(0)),torch.std(target_image[i].unsqueeze(0)))
        for j in range(n_source):
          images_data[images_data_length+1+j] = (torch.mean(image[j]),torch.std(image[j]))
        images_data_length = len(images_data)

        images.append(target_image[i].unsqueeze(0))
        images.append(image)

    # joint tensor
    images = torch.cat(images, 0)
    
    return images,images_data

if __name__ == '__main__':
  parser = argparse.ArgumentParser(description='Progressive Growing of GANs for test')
  parser.add_argument('test_path', type=str) #test_path = '/content/drive/MyDrive/Pre_Trained_Model/StyleGAN/andy_version4.model'
  parser.add_argument('--output_file', default='sample.png', type=str)
  args = parser.parse_args()
  device = 'cuda'
  generator = StyledGenerator(512).cuda()
  generator.load_state_dict(torch.load(args.test_path)['g_running'])
  generator.eval()

  mean_style = get_mean_style(generator, device)
  step = int(math.log(256, 2)) - 2
  img = sample(generator, step, mean_style, 3 * 5, device)
  utils.save_image(img, args.output_file, nrow=5, normalize=True, range=(-1, 1))
