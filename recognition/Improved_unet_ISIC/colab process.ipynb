{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCo11dsj_GPI",
        "outputId": "92c2d30e-3404-4b65-fc4c-f5dcbc3c5491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0,'/content/drive/My Drive/Colab Notebooks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P0HBw8xneJ_",
        "outputId": "fd9dd2ae-0371-4ac6-d099-78317c47875b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1051 files belonging to 1 classes.\n",
            "ISIC-2017_Training_Data: loading finished\n",
            "Found 1051 files belonging to 1 classes.\n",
            "ISIC-2017_Training_Part1_GroundTruth: loading finished\n",
            "Found 110 files belonging to 1 classes.\n",
            "ISIC-2017_Validation_Data: loading finished\n",
            "Found 110 files belonging to 1 classes.\n",
            "ISIC-2017_Validation_Part1_GroundTruth: loading finished\n",
            "Model build success\n"
          ]
        }
      ],
      "source": [
        "from modules import create_model\n",
        "from dataset import get_data\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "x_train = get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/train_data/\")\n",
        "x_train -= np.mean(x_train)\n",
        "y_train = get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/train_truth/\",is_y=True)\n",
        "x_validation = get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/validation_data/\")\n",
        "x_validation -= np.mean(x_validation)\n",
        "y_validation = get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/validation_truth/\",is_y=True)\n",
        "Improved_unet = create_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8m2MOt0-vkS",
        "outputId": "fa8073a6-32ab-4aaf-85ba-66e2dbec4212"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.6794 - accuracy: 0.6937 - val_loss: 0.6354 - val_accuracy: 0.7395\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.5356 - accuracy: 0.8024 - val_loss: 0.3658 - val_accuracy: 0.8967\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.4810 - accuracy: 0.8204 - val_loss: 0.4090 - val_accuracy: 0.8275\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.3650 - accuracy: 0.8583 - val_loss: 0.3628 - val_accuracy: 0.8512\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.3166 - accuracy: 0.8761 - val_loss: 0.3181 - val_accuracy: 0.8605\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.2894 - accuracy: 0.8840 - val_loss: 0.2554 - val_accuracy: 0.8947\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.2678 - accuracy: 0.8888 - val_loss: 0.2599 - val_accuracy: 0.9134\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.2447 - accuracy: 0.9014 - val_loss: 0.2371 - val_accuracy: 0.9081\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 4s 395ms/step - loss: 0.2210 - accuracy: 0.9081 - val_loss: 0.2300 - val_accuracy: 0.9116\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.2048 - accuracy: 0.9171 - val_loss: 0.1944 - val_accuracy: 0.9200\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.1907 - accuracy: 0.9223 - val_loss: 0.2311 - val_accuracy: 0.9073\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.1786 - accuracy: 0.9284 - val_loss: 0.1901 - val_accuracy: 0.9270\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.1736 - accuracy: 0.9305 - val_loss: 0.1845 - val_accuracy: 0.9324\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1596 - accuracy: 0.9352 - val_loss: 0.2154 - val_accuracy: 0.9092\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1537 - accuracy: 0.9374 - val_loss: 0.1748 - val_accuracy: 0.9302\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1488 - accuracy: 0.9407 - val_loss: 0.1737 - val_accuracy: 0.9289\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.1409 - accuracy: 0.9434 - val_loss: 0.1819 - val_accuracy: 0.9223\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.1312 - accuracy: 0.9460 - val_loss: 0.2705 - val_accuracy: 0.8859\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 4s 390ms/step - loss: 0.1267 - accuracy: 0.9478 - val_loss: 0.2535 - val_accuracy: 0.8988\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.1208 - accuracy: 0.9500 - val_loss: 0.1882 - val_accuracy: 0.9221\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1147 - accuracy: 0.9527 - val_loss: 0.2031 - val_accuracy: 0.9170\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1100 - accuracy: 0.9545 - val_loss: 0.2295 - val_accuracy: 0.9082\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.1012 - accuracy: 0.9575 - val_loss: 0.1713 - val_accuracy: 0.9343\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0985 - accuracy: 0.9585 - val_loss: 0.1497 - val_accuracy: 0.9446\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0962 - accuracy: 0.9594 - val_loss: 0.2503 - val_accuracy: 0.9137\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.0896 - accuracy: 0.9619 - val_loss: 0.1753 - val_accuracy: 0.9327\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0862 - accuracy: 0.9634 - val_loss: 0.1463 - val_accuracy: 0.9454\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0833 - accuracy: 0.9647 - val_loss: 0.2002 - val_accuracy: 0.9285\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.0797 - accuracy: 0.9658 - val_loss: 0.1741 - val_accuracy: 0.9418\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0774 - accuracy: 0.9670 - val_loss: 0.3128 - val_accuracy: 0.9056\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0779 - accuracy: 0.9665 - val_loss: 0.2352 - val_accuracy: 0.9240\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0725 - accuracy: 0.9691 - val_loss: 0.2028 - val_accuracy: 0.9317\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0730 - accuracy: 0.9685 - val_loss: 0.1753 - val_accuracy: 0.9466\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0697 - accuracy: 0.9702 - val_loss: 0.2281 - val_accuracy: 0.9277\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0676 - accuracy: 0.9710 - val_loss: 0.2021 - val_accuracy: 0.9369\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0654 - accuracy: 0.9717 - val_loss: 0.1886 - val_accuracy: 0.9445\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0677 - accuracy: 0.9709 - val_loss: 0.2513 - val_accuracy: 0.9217\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0630 - accuracy: 0.9730 - val_loss: 0.1936 - val_accuracy: 0.9419\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0620 - accuracy: 0.9734 - val_loss: 0.2844 - val_accuracy: 0.9160\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0598 - accuracy: 0.9743 - val_loss: 0.2453 - val_accuracy: 0.9358\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0568 - accuracy: 0.9756 - val_loss: 0.2153 - val_accuracy: 0.9375\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0568 - accuracy: 0.9756 - val_loss: 0.2506 - val_accuracy: 0.9280\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0554 - accuracy: 0.9761 - val_loss: 0.3031 - val_accuracy: 0.9201\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0543 - accuracy: 0.9767 - val_loss: 0.2266 - val_accuracy: 0.9372\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0516 - accuracy: 0.9777 - val_loss: 0.2508 - val_accuracy: 0.9307\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0500 - accuracy: 0.9784 - val_loss: 0.2845 - val_accuracy: 0.9289\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0485 - accuracy: 0.9792 - val_loss: 0.2615 - val_accuracy: 0.9310\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0476 - accuracy: 0.9796 - val_loss: 0.3746 - val_accuracy: 0.9118\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0480 - accuracy: 0.9793 - val_loss: 0.2957 - val_accuracy: 0.9234\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0458 - accuracy: 0.9803 - val_loss: 0.2584 - val_accuracy: 0.9358\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0455 - accuracy: 0.9804 - val_loss: 0.2685 - val_accuracy: 0.9339\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0463 - accuracy: 0.9801 - val_loss: 0.2465 - val_accuracy: 0.9363\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0477 - accuracy: 0.9795 - val_loss: 0.3660 - val_accuracy: 0.9168\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0463 - accuracy: 0.9801 - val_loss: 0.3313 - val_accuracy: 0.9204\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0436 - accuracy: 0.9812 - val_loss: 0.3180 - val_accuracy: 0.9272\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0432 - accuracy: 0.9814 - val_loss: 0.3559 - val_accuracy: 0.9212\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0415 - accuracy: 0.9821 - val_loss: 0.3918 - val_accuracy: 0.9183\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0405 - accuracy: 0.9827 - val_loss: 0.3878 - val_accuracy: 0.9176\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0402 - accuracy: 0.9827 - val_loss: 0.3161 - val_accuracy: 0.9319\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0403 - accuracy: 0.9827 - val_loss: 0.3498 - val_accuracy: 0.9248\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0401 - accuracy: 0.9828 - val_loss: 0.3962 - val_accuracy: 0.9160\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0386 - accuracy: 0.9834 - val_loss: 0.4298 - val_accuracy: 0.9132\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0386 - accuracy: 0.9833 - val_loss: 0.3448 - val_accuracy: 0.9257\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0376 - accuracy: 0.9839 - val_loss: 0.3732 - val_accuracy: 0.9221\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0370 - accuracy: 0.9841 - val_loss: 0.4060 - val_accuracy: 0.9181\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0365 - accuracy: 0.9843 - val_loss: 0.3719 - val_accuracy: 0.9240\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0359 - accuracy: 0.9846 - val_loss: 0.4355 - val_accuracy: 0.9130\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0353 - accuracy: 0.9848 - val_loss: 0.4135 - val_accuracy: 0.9185\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0358 - accuracy: 0.9846 - val_loss: 0.3881 - val_accuracy: 0.9210\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0346 - accuracy: 0.9851 - val_loss: 0.3677 - val_accuracy: 0.9281\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0339 - accuracy: 0.9854 - val_loss: 0.4261 - val_accuracy: 0.9221\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0340 - accuracy: 0.9855 - val_loss: 0.4765 - val_accuracy: 0.9152\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0336 - accuracy: 0.9855 - val_loss: 0.4778 - val_accuracy: 0.9164\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0342 - accuracy: 0.9853 - val_loss: 0.4600 - val_accuracy: 0.9173\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0338 - accuracy: 0.9856 - val_loss: 0.4011 - val_accuracy: 0.9261\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0332 - accuracy: 0.9858 - val_loss: 0.4176 - val_accuracy: 0.9217\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0328 - accuracy: 0.9859 - val_loss: 0.4322 - val_accuracy: 0.9225\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0327 - accuracy: 0.9860 - val_loss: 0.4100 - val_accuracy: 0.9221\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0323 - accuracy: 0.9862 - val_loss: 0.4189 - val_accuracy: 0.9221\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0318 - accuracy: 0.9863 - val_loss: 0.4432 - val_accuracy: 0.9226\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0319 - accuracy: 0.9863 - val_loss: 0.5119 - val_accuracy: 0.9138\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0323 - accuracy: 0.9861 - val_loss: 0.4435 - val_accuracy: 0.9220\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0316 - accuracy: 0.9864 - val_loss: 0.3994 - val_accuracy: 0.9302\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0311 - accuracy: 0.9867 - val_loss: 0.4227 - val_accuracy: 0.9268\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0310 - accuracy: 0.9866 - val_loss: 0.5032 - val_accuracy: 0.9166\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0309 - accuracy: 0.9867 - val_loss: 0.4556 - val_accuracy: 0.9230\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0302 - accuracy: 0.9870 - val_loss: 0.4546 - val_accuracy: 0.9247\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0301 - accuracy: 0.9871 - val_loss: 0.4747 - val_accuracy: 0.9204\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0298 - accuracy: 0.9872 - val_loss: 0.4969 - val_accuracy: 0.9202\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0298 - accuracy: 0.9873 - val_loss: 0.4206 - val_accuracy: 0.9242\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0300 - accuracy: 0.9871 - val_loss: 0.4724 - val_accuracy: 0.9212\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0296 - accuracy: 0.9873 - val_loss: 0.4993 - val_accuracy: 0.9196\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0296 - accuracy: 0.9873 - val_loss: 0.4336 - val_accuracy: 0.9283\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0290 - accuracy: 0.9876 - val_loss: 0.5065 - val_accuracy: 0.9206\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0290 - accuracy: 0.9876 - val_loss: 0.4564 - val_accuracy: 0.9237\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0293 - accuracy: 0.9874 - val_loss: 0.5177 - val_accuracy: 0.9168\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0296 - accuracy: 0.9873 - val_loss: 0.4912 - val_accuracy: 0.9207\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0286 - accuracy: 0.9877 - val_loss: 0.4615 - val_accuracy: 0.9247\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0286 - accuracy: 0.9877 - val_loss: 0.4975 - val_accuracy: 0.9229\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0282 - accuracy: 0.9879 - val_loss: 0.5102 - val_accuracy: 0.9214\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0284 - accuracy: 0.9878 - val_loss: 0.5188 - val_accuracy: 0.9199\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0279 - accuracy: 0.9881 - val_loss: 0.5044 - val_accuracy: 0.9232\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0289 - accuracy: 0.9876 - val_loss: 0.5242 - val_accuracy: 0.9167\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0282 - accuracy: 0.9879 - val_loss: 0.4800 - val_accuracy: 0.9251\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0276 - accuracy: 0.9881 - val_loss: 0.5416 - val_accuracy: 0.9190\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0275 - accuracy: 0.9882 - val_loss: 0.5062 - val_accuracy: 0.9231\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0272 - accuracy: 0.9884 - val_loss: 0.5506 - val_accuracy: 0.9210\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0273 - accuracy: 0.9883 - val_loss: 0.4909 - val_accuracy: 0.9267\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0267 - accuracy: 0.9886 - val_loss: 0.5565 - val_accuracy: 0.9191\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0268 - accuracy: 0.9885 - val_loss: 0.5231 - val_accuracy: 0.9208\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0266 - accuracy: 0.9886 - val_loss: 0.5208 - val_accuracy: 0.9226\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0264 - accuracy: 0.9887 - val_loss: 0.5482 - val_accuracy: 0.9221\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0262 - accuracy: 0.9887 - val_loss: 0.5309 - val_accuracy: 0.9235\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0260 - accuracy: 0.9888 - val_loss: 0.5343 - val_accuracy: 0.9230\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0262 - accuracy: 0.9888 - val_loss: 0.5346 - val_accuracy: 0.9230\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0258 - accuracy: 0.9889 - val_loss: 0.5515 - val_accuracy: 0.9218\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0256 - accuracy: 0.9890 - val_loss: 0.5064 - val_accuracy: 0.9271\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0257 - accuracy: 0.9890 - val_loss: 0.5129 - val_accuracy: 0.9264\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0256 - accuracy: 0.9890 - val_loss: 0.5063 - val_accuracy: 0.9272\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0255 - accuracy: 0.9891 - val_loss: 0.5895 - val_accuracy: 0.9187\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0253 - accuracy: 0.9891 - val_loss: 0.5186 - val_accuracy: 0.9280\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.5457 - val_accuracy: 0.9243\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0252 - accuracy: 0.9892 - val_loss: 0.5836 - val_accuracy: 0.9199\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0253 - accuracy: 0.9891 - val_loss: 0.5740 - val_accuracy: 0.9207\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.0253 - accuracy: 0.9892 - val_loss: 0.5403 - val_accuracy: 0.9259\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0251 - accuracy: 0.9893 - val_loss: 0.5604 - val_accuracy: 0.9249\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0251 - accuracy: 0.9893 - val_loss: 0.5754 - val_accuracy: 0.9217\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0249 - accuracy: 0.9894 - val_loss: 0.5582 - val_accuracy: 0.9247\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0248 - accuracy: 0.9893 - val_loss: 0.5754 - val_accuracy: 0.9243\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.5853 - val_accuracy: 0.9210\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0243 - accuracy: 0.9896 - val_loss: 0.5770 - val_accuracy: 0.9229\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0244 - accuracy: 0.9896 - val_loss: 0.5858 - val_accuracy: 0.9221\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 0.5705 - val_accuracy: 0.9253\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0244 - accuracy: 0.9896 - val_loss: 0.5424 - val_accuracy: 0.9280\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0242 - accuracy: 0.9897 - val_loss: 0.6137 - val_accuracy: 0.9215\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0245 - accuracy: 0.9895 - val_loss: 0.5479 - val_accuracy: 0.9275\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0243 - accuracy: 0.9896 - val_loss: 0.5687 - val_accuracy: 0.9244\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0243 - accuracy: 0.9896 - val_loss: 0.6024 - val_accuracy: 0.9204\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0242 - accuracy: 0.9896 - val_loss: 0.5711 - val_accuracy: 0.9249\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0238 - accuracy: 0.9898 - val_loss: 0.6376 - val_accuracy: 0.9189\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0236 - accuracy: 0.9899 - val_loss: 0.5859 - val_accuracy: 0.9241\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0236 - accuracy: 0.9899 - val_loss: 0.5826 - val_accuracy: 0.9258\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0236 - accuracy: 0.9899 - val_loss: 0.5951 - val_accuracy: 0.9244\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0234 - accuracy: 0.9900 - val_loss: 0.5954 - val_accuracy: 0.9230\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0233 - accuracy: 0.9900 - val_loss: 0.5805 - val_accuracy: 0.9263\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0235 - accuracy: 0.9899 - val_loss: 0.5741 - val_accuracy: 0.9263\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0232 - accuracy: 0.9901 - val_loss: 0.5874 - val_accuracy: 0.9255\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0231 - accuracy: 0.9901 - val_loss: 0.6087 - val_accuracy: 0.9241\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0233 - accuracy: 0.9901 - val_loss: 0.5843 - val_accuracy: 0.9265\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0230 - accuracy: 0.9902 - val_loss: 0.6002 - val_accuracy: 0.9246\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0234 - accuracy: 0.9900 - val_loss: 0.6380 - val_accuracy: 0.9203\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0230 - accuracy: 0.9901 - val_loss: 0.5795 - val_accuracy: 0.9266\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0228 - accuracy: 0.9903 - val_loss: 0.5847 - val_accuracy: 0.9270\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0227 - accuracy: 0.9903 - val_loss: 0.6128 - val_accuracy: 0.9243\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0225 - accuracy: 0.9904 - val_loss: 0.6145 - val_accuracy: 0.9238\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0228 - accuracy: 0.9903 - val_loss: 0.5677 - val_accuracy: 0.9290\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0229 - accuracy: 0.9902 - val_loss: 0.5910 - val_accuracy: 0.9248\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0224 - accuracy: 0.9904 - val_loss: 0.6222 - val_accuracy: 0.9250\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0225 - accuracy: 0.9904 - val_loss: 0.6363 - val_accuracy: 0.9239\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0224 - accuracy: 0.9904 - val_loss: 0.6334 - val_accuracy: 0.9229\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0224 - accuracy: 0.9904 - val_loss: 0.6141 - val_accuracy: 0.9246\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0224 - accuracy: 0.9904 - val_loss: 0.6639 - val_accuracy: 0.9212\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0223 - accuracy: 0.9904 - val_loss: 0.6473 - val_accuracy: 0.9211\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0221 - accuracy: 0.9906 - val_loss: 0.6180 - val_accuracy: 0.9263\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0221 - accuracy: 0.9906 - val_loss: 0.6531 - val_accuracy: 0.9230\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0221 - accuracy: 0.9906 - val_loss: 0.6470 - val_accuracy: 0.9237\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0223 - accuracy: 0.9905 - val_loss: 0.6142 - val_accuracy: 0.9255\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0221 - accuracy: 0.9906 - val_loss: 0.5955 - val_accuracy: 0.9277\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0222 - accuracy: 0.9905 - val_loss: 0.5939 - val_accuracy: 0.9285\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0221 - accuracy: 0.9906 - val_loss: 0.6238 - val_accuracy: 0.9237\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0221 - accuracy: 0.9905 - val_loss: 0.6501 - val_accuracy: 0.9232\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0219 - accuracy: 0.9906 - val_loss: 0.6178 - val_accuracy: 0.9264\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0219 - accuracy: 0.9907 - val_loss: 0.6519 - val_accuracy: 0.9229\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0219 - accuracy: 0.9906 - val_loss: 0.6438 - val_accuracy: 0.9247\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0217 - accuracy: 0.9907 - val_loss: 0.6621 - val_accuracy: 0.9233\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0217 - accuracy: 0.9908 - val_loss: 0.6624 - val_accuracy: 0.9230\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0216 - accuracy: 0.9908 - val_loss: 0.6701 - val_accuracy: 0.9224\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0216 - accuracy: 0.9907 - val_loss: 0.6684 - val_accuracy: 0.9220\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0216 - accuracy: 0.9908 - val_loss: 0.6383 - val_accuracy: 0.9253\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0215 - accuracy: 0.9909 - val_loss: 0.6509 - val_accuracy: 0.9234\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0215 - accuracy: 0.9908 - val_loss: 0.6360 - val_accuracy: 0.9266\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0215 - accuracy: 0.9908 - val_loss: 0.6029 - val_accuracy: 0.9285\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0216 - accuracy: 0.9907 - val_loss: 0.6544 - val_accuracy: 0.9240\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 0.6236 - val_accuracy: 0.9281\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 0.6570 - val_accuracy: 0.9236\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0212 - accuracy: 0.9910 - val_loss: 0.6394 - val_accuracy: 0.9256\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 0.6467 - val_accuracy: 0.9260\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0212 - accuracy: 0.9909 - val_loss: 0.6548 - val_accuracy: 0.9243\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0214 - accuracy: 0.9909 - val_loss: 0.6498 - val_accuracy: 0.9257\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0211 - accuracy: 0.9910 - val_loss: 0.6626 - val_accuracy: 0.9241\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0211 - accuracy: 0.9910 - val_loss: 0.6368 - val_accuracy: 0.9270\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0211 - accuracy: 0.9910 - val_loss: 0.6419 - val_accuracy: 0.9266\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0210 - accuracy: 0.9911 - val_loss: 0.6427 - val_accuracy: 0.9264\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0211 - accuracy: 0.9910 - val_loss: 0.6627 - val_accuracy: 0.9248\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0211 - accuracy: 0.9910 - val_loss: 0.6771 - val_accuracy: 0.9230\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.6823 - val_accuracy: 0.9235\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0208 - accuracy: 0.9911 - val_loss: 0.6823 - val_accuracy: 0.9237\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.7023 - val_accuracy: 0.9218\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.6988 - val_accuracy: 0.9231\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0210 - accuracy: 0.9911 - val_loss: 0.6645 - val_accuracy: 0.9252\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 0.6755 - val_accuracy: 0.9243\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.6899 - val_accuracy: 0.9229\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.6960 - val_accuracy: 0.9241\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.6637 - val_accuracy: 0.9270\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.6692 - val_accuracy: 0.9247\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.6711 - val_accuracy: 0.9257\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0205 - accuracy: 0.9912 - val_loss: 0.6748 - val_accuracy: 0.9250\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.6571 - val_accuracy: 0.9279\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.6868 - val_accuracy: 0.9239\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.7198 - val_accuracy: 0.9223\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0205 - accuracy: 0.9912 - val_loss: 0.6647 - val_accuracy: 0.9265\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.6928 - val_accuracy: 0.9246\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.6999 - val_accuracy: 0.9238\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.6878 - val_accuracy: 0.9252\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.6920 - val_accuracy: 0.9251\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.6896 - val_accuracy: 0.9245\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 0.6812 - val_accuracy: 0.9259\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0203 - accuracy: 0.9913 - val_loss: 0.7126 - val_accuracy: 0.9229\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0203 - accuracy: 0.9913 - val_loss: 0.6805 - val_accuracy: 0.9260\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0205 - accuracy: 0.9912 - val_loss: 0.7058 - val_accuracy: 0.9236\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 0.7158 - val_accuracy: 0.9229\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0203 - accuracy: 0.9914 - val_loss: 0.6700 - val_accuracy: 0.9263\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0203 - accuracy: 0.9914 - val_loss: 0.6892 - val_accuracy: 0.9253\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0201 - accuracy: 0.9914 - val_loss: 0.7139 - val_accuracy: 0.9234\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0202 - accuracy: 0.9914 - val_loss: 0.6949 - val_accuracy: 0.9247\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0203 - accuracy: 0.9913 - val_loss: 0.7122 - val_accuracy: 0.9233\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0201 - accuracy: 0.9914 - val_loss: 0.7131 - val_accuracy: 0.9240\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0203 - accuracy: 0.9914 - val_loss: 0.6926 - val_accuracy: 0.9252\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0202 - accuracy: 0.9914 - val_loss: 0.7256 - val_accuracy: 0.9231\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0201 - accuracy: 0.9915 - val_loss: 0.6994 - val_accuracy: 0.9244\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.7175 - val_accuracy: 0.9237\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0200 - accuracy: 0.9914 - val_loss: 0.7091 - val_accuracy: 0.9246\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0201 - accuracy: 0.9914 - val_loss: 0.7122 - val_accuracy: 0.9249\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0201 - accuracy: 0.9914 - val_loss: 0.6991 - val_accuracy: 0.9245\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0201 - accuracy: 0.9914 - val_loss: 0.7093 - val_accuracy: 0.9243\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.7203 - val_accuracy: 0.9235\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7361 - val_accuracy: 0.9234\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0200 - accuracy: 0.9915 - val_loss: 0.7222 - val_accuracy: 0.9232\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0198 - accuracy: 0.9915 - val_loss: 0.7149 - val_accuracy: 0.9238\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7112 - val_accuracy: 0.9249\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.7141 - val_accuracy: 0.9247\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7406 - val_accuracy: 0.9223\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 4s 388ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7253 - val_accuracy: 0.9239\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.7196 - val_accuracy: 0.9246\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0199 - accuracy: 0.9915 - val_loss: 0.7170 - val_accuracy: 0.9244\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0198 - accuracy: 0.9915 - val_loss: 0.7201 - val_accuracy: 0.9243\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7153 - val_accuracy: 0.9248\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7223 - val_accuracy: 0.9245\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7326 - val_accuracy: 0.9235\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.7250 - val_accuracy: 0.9243\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.7225 - val_accuracy: 0.9245\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7239 - val_accuracy: 0.9240\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7299 - val_accuracy: 0.9243\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7167 - val_accuracy: 0.9249\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7301 - val_accuracy: 0.9242\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7184 - val_accuracy: 0.9244\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7142 - val_accuracy: 0.9246\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 0.7147 - val_accuracy: 0.9251\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7310 - val_accuracy: 0.9245\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0198 - accuracy: 0.9916 - val_loss: 0.7268 - val_accuracy: 0.9242\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7263 - val_accuracy: 0.9242\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7352 - val_accuracy: 0.9242\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7403 - val_accuracy: 0.9230\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0196 - accuracy: 0.9916 - val_loss: 0.7345 - val_accuracy: 0.9241\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7168 - val_accuracy: 0.9254\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7272 - val_accuracy: 0.9246\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7288 - val_accuracy: 0.9244\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7231 - val_accuracy: 0.9251\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7387 - val_accuracy: 0.9239\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7514 - val_accuracy: 0.9228\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7255 - val_accuracy: 0.9247\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7228 - val_accuracy: 0.9252\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7265 - val_accuracy: 0.9248\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7578 - val_accuracy: 0.9227\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7560 - val_accuracy: 0.9227\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7118 - val_accuracy: 0.9262\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0196 - accuracy: 0.9917 - val_loss: 0.7246 - val_accuracy: 0.9255\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7307 - val_accuracy: 0.9247\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7422 - val_accuracy: 0.9236\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7270 - val_accuracy: 0.9252\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0195 - accuracy: 0.9917 - val_loss: 0.7266 - val_accuracy: 0.9254\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7380 - val_accuracy: 0.9243\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 4s 385ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7374 - val_accuracy: 0.9247\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 4s 383ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7439 - val_accuracy: 0.9245\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0194 - accuracy: 0.9917 - val_loss: 0.7527 - val_accuracy: 0.9235\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7518 - val_accuracy: 0.9237\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7417 - val_accuracy: 0.9245\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0192 - accuracy: 0.9918 - val_loss: 0.7470 - val_accuracy: 0.9243\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 4s 386ms/step - loss: 0.0192 - accuracy: 0.9919 - val_loss: 0.7532 - val_accuracy: 0.9241\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7465 - val_accuracy: 0.9239\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7438 - val_accuracy: 0.9246\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0194 - accuracy: 0.9918 - val_loss: 0.7495 - val_accuracy: 0.9239\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 4s 387ms/step - loss: 0.0192 - accuracy: 0.9918 - val_loss: 0.7531 - val_accuracy: 0.9236\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7665 - val_accuracy: 0.9224\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7647 - val_accuracy: 0.9228\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 4s 384ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7602 - val_accuracy: 0.9236\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 4s 382ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7558 - val_accuracy: 0.9236\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0192 - accuracy: 0.9918 - val_loss: 0.7491 - val_accuracy: 0.9235\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0194 - accuracy: 0.9918 - val_loss: 0.7466 - val_accuracy: 0.9244\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 4s 381ms/step - loss: 0.0193 - accuracy: 0.9918 - val_loss: 0.7376 - val_accuracy: 0.9248\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60e0a7ff90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\n",
        "# need improvement, should add a weight decay to LR, +\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0005,\n",
        "    decay_steps=11,\n",
        "    decay_rate=0.985\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    numerator = 2 * tf.reduce_sum(y_true * y_pred) + 1e-6\n",
        "    denominator = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-6\n",
        "    \n",
        "    return  1-numerator / denominator\n",
        "\n",
        "# need a dice loss function\n",
        "Improved_unet.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'],run_eagerly=True)\n",
        "\n",
        "Improved_unet.fit(x_train, y_train,\n",
        "                  batch_size=100,\n",
        "                  epochs=300,\n",
        "                  shuffle=True,\n",
        "                  validation_data=(x_validation, y_validation),\n",
        "                  steps_per_epoch=11\n",
        "                  )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRJyO04QpaVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cbc83f-3a52-4ff9-abe0-d8621991084d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 219 files belonging to 1 classes.\n",
            "ISIC-2017_Test_v2_Data: loading finished\n",
            "7/7 [==============================] - 0s 46ms/step\n",
            "[[[[9.99154449e-01 8.45586183e-04 0.00000000e+00]\n",
            "   [9.99945760e-01 5.42408779e-05 0.00000000e+00]\n",
            "   [9.99996185e-01 3.78329310e-06 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99732435e-01 2.67496303e-04 0.00000000e+00]\n",
            "   [9.98404920e-01 1.59504241e-03 0.00000000e+00]\n",
            "   [9.88924921e-01 1.10750375e-02 0.00000000e+00]]\n",
            "\n",
            "  [[9.99953747e-01 4.62245771e-05 0.00000000e+00]\n",
            "   [9.99999762e-01 2.03600010e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 3.39539108e-09 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99997973e-01 2.04994149e-06 0.00000000e+00]\n",
            "   [9.99973655e-01 2.63743896e-05 0.00000000e+00]\n",
            "   [9.98997509e-01 1.00246898e-03 0.00000000e+00]]\n",
            "\n",
            "  [[9.99997497e-01 2.49434584e-06 0.00000000e+00]\n",
            "   [1.00000000e+00 1.47419255e-09 0.00000000e+00]\n",
            "   [1.00000000e+00 6.20288022e-12 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 3.09370520e-08 0.00000000e+00]\n",
            "   [9.99998927e-01 1.02991942e-06 0.00000000e+00]\n",
            "   [9.99910831e-01 8.91582604e-05 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[1.00000000e+00 1.84172428e-08 0.00000000e+00]\n",
            "   [1.00000000e+00 2.74164290e-13 0.00000000e+00]\n",
            "   [1.00000000e+00 5.50181304e-16 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.75305974e-18 0.00000000e+00]\n",
            "   [1.00000000e+00 4.55472962e-16 0.00000000e+00]\n",
            "   [1.00000000e+00 2.29619882e-11 0.00000000e+00]]\n",
            "\n",
            "  [[9.99999166e-01 8.85998077e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 6.30893462e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 9.72259653e-14 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.39322679e-15 0.00000000e+00]\n",
            "   [1.00000000e+00 9.94321880e-14 0.00000000e+00]\n",
            "   [1.00000000e+00 1.11706389e-09 0.00000000e+00]]\n",
            "\n",
            "  [[9.99923944e-01 7.60259500e-05 0.00000000e+00]\n",
            "   [9.99999642e-01 3.69966671e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 3.88974009e-09 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 3.56586538e-10 0.00000000e+00]\n",
            "   [1.00000000e+00 4.69507366e-09 0.00000000e+00]\n",
            "   [9.99999166e-01 8.93294612e-07 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[9.99982715e-01 1.73150238e-05 0.00000000e+00]\n",
            "   [9.99999642e-01 2.98720835e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 3.56042373e-09 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99890447e-01 1.09534900e-04 0.00000000e+00]\n",
            "   [9.99240279e-01 7.59753166e-04 0.00000000e+00]\n",
            "   [9.93082404e-01 6.91762893e-03 0.00000000e+00]]\n",
            "\n",
            "  [[9.99999881e-01 1.60013229e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 3.38308583e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 3.77712388e-14 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99999404e-01 6.13857139e-07 0.00000000e+00]\n",
            "   [9.99990821e-01 9.22660274e-06 0.00000000e+00]\n",
            "   [9.99470413e-01 5.29549317e-04 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 7.95073007e-10 0.00000000e+00]\n",
            "   [1.00000000e+00 4.75862813e-15 0.00000000e+00]\n",
            "   [1.00000000e+00 3.52659200e-19 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 7.04326197e-09 0.00000000e+00]\n",
            "   [9.99999642e-01 3.38074358e-07 0.00000000e+00]\n",
            "   [9.99953866e-01 4.61719756e-05 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.98224318e-01 1.77568989e-03 0.00000000e+00]\n",
            "   [9.99966383e-01 3.35759723e-05 0.00000000e+00]\n",
            "   [9.99997854e-01 2.15428418e-06 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.29151200e-15 0.00000000e+00]\n",
            "   [1.00000000e+00 3.07188872e-13 0.00000000e+00]\n",
            "   [1.00000000e+00 2.86219626e-09 0.00000000e+00]]\n",
            "\n",
            "  [[9.94635165e-01 5.36480499e-03 0.00000000e+00]\n",
            "   [9.99796093e-01 2.03917531e-04 0.00000000e+00]\n",
            "   [9.99979973e-01 2.00769155e-05 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.82155945e-13 0.00000000e+00]\n",
            "   [1.00000000e+00 2.03465318e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 4.77962168e-08 0.00000000e+00]]\n",
            "\n",
            "  [[9.76579368e-01 2.34205779e-02 0.00000000e+00]\n",
            "   [9.96292412e-01 3.70758749e-03 0.00000000e+00]\n",
            "   [9.99147892e-01 8.52087513e-04 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 6.53002452e-09 0.00000000e+00]\n",
            "   [9.99999881e-01 1.45288539e-07 0.00000000e+00]\n",
            "   [9.99989390e-01 1.05804256e-05 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[9.99998450e-01 1.52794360e-06 0.00000000e+00]\n",
            "   [1.00000000e+00 8.19321944e-09 0.00000000e+00]\n",
            "   [1.00000000e+00 5.13137761e-11 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99943018e-01 5.69597105e-05 0.00000000e+00]\n",
            "   [9.99627233e-01 3.72755283e-04 0.00000000e+00]\n",
            "   [9.96113300e-01 3.88664519e-03 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 5.00368857e-09 0.00000000e+00]\n",
            "   [1.00000000e+00 1.33253068e-13 0.00000000e+00]\n",
            "   [1.00000000e+00 6.13787668e-17 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99999762e-01 1.96829177e-07 0.00000000e+00]\n",
            "   [9.99997497e-01 2.46496370e-06 0.00000000e+00]\n",
            "   [9.99798954e-01 2.01116709e-04 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 1.22082622e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 7.87796889e-18 0.00000000e+00]\n",
            "   [1.00000000e+00 1.58867814e-22 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.86878210e-09 0.00000000e+00]\n",
            "   [9.99999881e-01 6.19488745e-08 0.00000000e+00]\n",
            "   [9.99985814e-01 1.42088329e-05 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.98778522e-01 1.22141757e-03 0.00000000e+00]\n",
            "   [9.99978423e-01 2.16085664e-05 0.00000000e+00]\n",
            "   [9.99997497e-01 2.46181799e-06 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 3.48026751e-21 0.00000000e+00]\n",
            "   [1.00000000e+00 9.13243172e-19 0.00000000e+00]\n",
            "   [1.00000000e+00 2.72905911e-13 0.00000000e+00]]\n",
            "\n",
            "  [[9.96033728e-01 3.96624068e-03 0.00000000e+00]\n",
            "   [9.99885917e-01 1.14020564e-04 0.00000000e+00]\n",
            "   [9.99982953e-01 1.70917065e-05 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 3.64372109e-18 0.00000000e+00]\n",
            "   [1.00000000e+00 2.10975128e-16 0.00000000e+00]\n",
            "   [1.00000000e+00 1.44547898e-11 0.00000000e+00]]\n",
            "\n",
            "  [[9.81420338e-01 1.85796153e-02 0.00000000e+00]\n",
            "   [9.97510433e-01 2.48960801e-03 0.00000000e+00]\n",
            "   [9.99290347e-01 7.09670421e-04 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 4.31686674e-12 0.00000000e+00]\n",
            "   [1.00000000e+00 7.17748708e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 4.23115942e-08 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[9.99986172e-01 1.38476416e-05 0.00000000e+00]\n",
            "   [9.99999762e-01 2.16235776e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 5.50645174e-09 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99996901e-01 3.14682575e-06 0.00000000e+00]\n",
            "   [9.99920011e-01 7.99549161e-05 0.00000000e+00]\n",
            "   [9.98347878e-01 1.65209838e-03 0.00000000e+00]]\n",
            "\n",
            "  [[9.99999881e-01 1.01133061e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 1.96381088e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 7.37621769e-14 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.50471113e-09 0.00000000e+00]\n",
            "   [9.99999881e-01 1.24429477e-07 0.00000000e+00]\n",
            "   [9.99957681e-01 4.23073252e-05 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 4.44451725e-10 0.00000000e+00]\n",
            "   [1.00000000e+00 2.75111092e-15 0.00000000e+00]\n",
            "   [1.00000000e+00 1.51246470e-18 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.13481989e-12 0.00000000e+00]\n",
            "   [1.00000000e+00 3.65568104e-10 0.00000000e+00]\n",
            "   [9.99999404e-01 6.00816350e-07 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.99888778e-01 1.11203844e-04 0.00000000e+00]\n",
            "   [9.99999285e-01 7.51512573e-07 0.00000000e+00]\n",
            "   [9.99999881e-01 9.31588957e-08 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.84929933e-23 0.00000000e+00]\n",
            "   [1.00000000e+00 3.81108830e-20 0.00000000e+00]\n",
            "   [1.00000000e+00 4.87963382e-14 0.00000000e+00]]\n",
            "\n",
            "  [[9.99526978e-01 4.73081687e-04 0.00000000e+00]\n",
            "   [9.99994040e-01 5.90963054e-06 0.00000000e+00]\n",
            "   [9.99999285e-01 7.34601031e-07 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.26279525e-19 0.00000000e+00]\n",
            "   [1.00000000e+00 2.46232676e-17 0.00000000e+00]\n",
            "   [1.00000000e+00 4.68132260e-12 0.00000000e+00]]\n",
            "\n",
            "  [[9.94675756e-01 5.32427803e-03 0.00000000e+00]\n",
            "   [9.99579608e-01 4.20401833e-04 0.00000000e+00]\n",
            "   [9.99892473e-01 1.07524545e-04 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 6.69426970e-13 0.00000000e+00]\n",
            "   [1.00000000e+00 2.49266198e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 2.27385293e-08 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[9.99999881e-01 6.68128735e-08 0.00000000e+00]\n",
            "   [1.00000000e+00 1.03337082e-10 0.00000000e+00]\n",
            "   [1.00000000e+00 8.09641728e-14 0.00000000e+00]\n",
            "   ...\n",
            "   [9.98112917e-01 1.88705279e-03 0.00000000e+00]\n",
            "   [9.92296517e-01 7.70342490e-03 0.00000000e+00]\n",
            "   [9.68799829e-01 3.12001798e-02 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 5.49589020e-11 0.00000000e+00]\n",
            "   [1.00000000e+00 9.79902307e-17 0.00000000e+00]\n",
            "   [1.00000000e+00 1.95997639e-21 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99932647e-01 6.73577088e-05 0.00000000e+00]\n",
            "   [9.99545157e-01 4.54770430e-04 0.00000000e+00]\n",
            "   [9.94086027e-01 5.91401197e-03 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 2.12555837e-14 0.00000000e+00]\n",
            "   [1.00000000e+00 2.35616874e-22 0.00000000e+00]\n",
            "   [1.00000000e+00 8.58746343e-29 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99994993e-01 4.97262636e-06 0.00000000e+00]\n",
            "   [9.99938846e-01 6.11447394e-05 0.00000000e+00]\n",
            "   [9.98830140e-01 1.16982346e-03 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.99637008e-01 3.63013067e-04 0.00000000e+00]\n",
            "   [9.99997139e-01 2.86994941e-06 0.00000000e+00]\n",
            "   [9.99999762e-01 2.84492870e-07 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.01129069e-36 0.00000000e+00]\n",
            "   [1.00000000e+00 1.74169471e-31 0.00000000e+00]\n",
            "   [1.00000000e+00 8.94059054e-22 0.00000000e+00]]\n",
            "\n",
            "  [[9.98187482e-01 1.81248365e-03 0.00000000e+00]\n",
            "   [9.99968290e-01 3.16661208e-05 0.00000000e+00]\n",
            "   [9.99996662e-01 3.33335652e-06 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 9.59982602e-31 0.00000000e+00]\n",
            "   [1.00000000e+00 5.92251114e-27 0.00000000e+00]\n",
            "   [1.00000000e+00 1.34900636e-18 0.00000000e+00]]\n",
            "\n",
            "  [[9.86152649e-01 1.38473473e-02 0.00000000e+00]\n",
            "   [9.98709202e-01 1.29084277e-03 0.00000000e+00]\n",
            "   [9.99702394e-01 2.97568127e-04 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 5.31731440e-20 0.00000000e+00]\n",
            "   [1.00000000e+00 2.04996366e-17 0.00000000e+00]\n",
            "   [1.00000000e+00 9.51162651e-13 0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[9.99999166e-01 8.48072432e-07 0.00000000e+00]\n",
            "   [1.00000000e+00 3.93399979e-09 0.00000000e+00]\n",
            "   [1.00000000e+00 2.43006639e-11 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99845743e-01 1.54288486e-04 0.00000000e+00]\n",
            "   [9.98979628e-01 1.02036772e-03 0.00000000e+00]\n",
            "   [9.91686404e-01 8.31354503e-03 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 1.61618952e-09 0.00000000e+00]\n",
            "   [1.00000000e+00 2.49753153e-14 0.00000000e+00]\n",
            "   [1.00000000e+00 1.09518812e-17 0.00000000e+00]\n",
            "   ...\n",
            "   [9.99998808e-01 1.15715147e-06 0.00000000e+00]\n",
            "   [9.99986529e-01 1.34962502e-05 0.00000000e+00]\n",
            "   [9.99333680e-01 6.66281150e-04 0.00000000e+00]]\n",
            "\n",
            "  [[1.00000000e+00 1.30223946e-12 0.00000000e+00]\n",
            "   [1.00000000e+00 2.39500272e-19 0.00000000e+00]\n",
            "   [1.00000000e+00 6.65625291e-24 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 1.77068582e-08 0.00000000e+00]\n",
            "   [9.99999523e-01 4.24661806e-07 0.00000000e+00]\n",
            "   [9.99957204e-01 4.27465711e-05 0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[9.97822881e-01 2.17712903e-03 0.00000000e+00]\n",
            "   [9.99957800e-01 4.21557743e-05 0.00000000e+00]\n",
            "   [9.99996901e-01 3.07063056e-06 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 5.94019869e-29 0.00000000e+00]\n",
            "   [1.00000000e+00 6.81201803e-25 0.00000000e+00]\n",
            "   [1.00000000e+00 2.90649231e-17 0.00000000e+00]]\n",
            "\n",
            "  [[9.93807137e-01 6.19286112e-03 0.00000000e+00]\n",
            "   [9.99798954e-01 2.01041737e-04 0.00000000e+00]\n",
            "   [9.99981642e-01 1.83994471e-05 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 2.90526230e-24 0.00000000e+00]\n",
            "   [1.00000000e+00 2.56654111e-21 0.00000000e+00]\n",
            "   [1.00000000e+00 9.41207002e-15 0.00000000e+00]]\n",
            "\n",
            "  [[9.69233453e-01 3.07664871e-02 0.00000000e+00]\n",
            "   [9.96112943e-01 3.88707896e-03 0.00000000e+00]\n",
            "   [9.99241710e-01 7.58252223e-04 0.00000000e+00]\n",
            "   ...\n",
            "   [1.00000000e+00 7.80094210e-16 0.00000000e+00]\n",
            "   [1.00000000e+00 8.10978617e-14 0.00000000e+00]\n",
            "   [1.00000000e+00 3.73376025e-10 0.00000000e+00]]]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x_test = get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/test_data/\")\n",
        "output=Improved_unet.predict(x_test)\n",
        "\n",
        "output=output[:,:,:,1:2,:]\n",
        "output=np.squeeze(output)\n",
        "output = np.insert(output, 2, 0, axis=3)\n",
        "\n",
        "output = np.where(output > 0.5, float(1), float(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzFNP9UuxKKT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "8aedfa7b-cfb3-43bd-f97a-16eb44a476a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(output[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate the dice similarity coeffient\n"
      ],
      "metadata": {
        "id": "ZRx5veEcmht0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=get_data(\"/content/drive/My Drive/Colab Notebooks/COMP3710-report/dataset/test_truth/\",is_y=True)\n",
        "\n",
        "y_test = y_test[:, :, :, 1:2, :]\n",
        "y_test = np.squeeze(y_test)\n",
        "y_test = np.insert(y_test, 2, 0, axis=3)\n",
        "y_test = np.where(y_test > 0.5, float(1), float(0))\n",
        "dice_similarity=1-dice_loss(output,y_test)\n",
        "print(dice_similarity.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Mj4TI-mhcw",
        "outputId": "f2e6ccd5-6ade-47cd-a12d-58e00c713b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 219 files belonging to 1 classes.\n",
            "ISIC-2017_Test_v2_Part1_GroundTruth: loading finished\n",
            "0.8547709\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}