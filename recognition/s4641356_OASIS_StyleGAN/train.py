import tensorflow as tf
import numpy as np
import GANutils
import modules
import dataset
import os


def fit(
        style_GAN: modules.StyleGAN, 
        data_loader: dataset.OASIS_loader, 
        batch_size: int, 
        epochs: int, 
        training_history_location: str, 
        image_sample_count:int = 5, 
        image_sample_output:str = "output/", 
        model_output:str = "model/"
        ) -> None:
    """
    Fits the model to a given set of training images. Upon conclusion of an
    epoch, the epoch's training history is saved to disk. If requested, 
    sample images are also taken and the model's current state is saved to 
    disk at the end of each epoch as well (either functionality can be 
    disabled by passing None as the repsective filepath). We save after 
    every epoch to protect against disruption during training. the styleGAN 
    class and this fit method can pick up training again from where it has 
    been left off. Training history is appended, without overwriting 
    existing data.  

    The custom GAN training paradigm is as follows:
        - Take a batch of real sample images, and train the discriminator to 
            report a high "realness" score when it sees such an image.
        - Generate an equivilantly sized batch of fake image using the 
            generator and its current set of weights. Then, train the 
            discrimimator to report a low "realness" score upon seeing such 
            images.
        - Train the generator to produce images that make the discriminator, 
            now with its newly trained weights, output a high "realness" score. 
            The generator must adapt weights as the discriminator has just been 
            trained on its current configuration.
        
        The loss used to achieve this training is applying the softplus function 
        to the output of the discriminator. This function is strictly positive 
        and assymtotes towards zero as the input becomes more negative. Hence 
        taking the negative of the result of the discriminator when trained on 
        real images and applying softplus will yield lower loss the higher the 
        'realness' score provided. Contrariwise taking the result of the 
        discriminator directly when trained on fake images and applying softplus 
        will yield lower loss the lower the 'realness' score provided. To apply 
        this loss to the generator, the composed system 
        (discriminator(generator)) is trained on random inputs to yield the 
        realness score and subsequent loss of the images generated by the 
        generator. The assotiated gradient is then computed with respect to, and 
        then applied to, only the generator's parameters.

    Args:
        style_GAN (modules.StyleGAN): styleGAN to fit on given images
        data_loader (dataset.OASIS_loader): Data loader to draw image data from
        batch_size (int): Number of images to pass through model per batch. 
                Making this a power of 2 is reccommended. Precondition: positive
        epochs (int): Number of epochs (repeat runs of full training set) to 
                train model on. Precondition: positive.
        training_history_location (str): Filepath of csv (no file extension) to 
                save training history. If a folder path is provided it must 
                be valid.
        image_sample_count (int, optional): Number of image samples to take per 
                epoch ignored if image_sample_output is set to None. 
                Precondition: positive. Defaults to 5
        image_sample_output (str, optional): Directory to save sample images 
                after each epoch, or set to None to disable saving. 
                Defaults to "output/".
        model_output (str, optional): Directory save model information after 
                each epoch, or set to None to disable model saving. 
                Defaults to "model/". 
    """
    #batches round down coverage, preventing duplicates per epoch
    num_batches = data_loader.get_num_images_availible()//batch_size 
    style_GAN.track_mean(data_loader.get_mean())

    #start with zeros as the background of OASIS images are black
    batch_generator_base = np.repeat(style_GAN.get_generator_base(), 
            batch_size, axis = 0)
    
    #Conduct training
    for e in range(epochs):
        print(">> epoch {}/{}".format(e+1,epochs))
        epoch_metrics = {metric: [] for metric in modules.StyleGAN.METRICS}
        for b in range(num_batches):
            print(">>>> batch {}/{}: ".format(b+1,num_batches), end ="")

            #train discriminator on real images
            with tf.GradientTape() as tape:
                batch = data_loader.get_data(batch_size)
                real_logits = style_GAN.discriminator(batch)
                #softplus is a strictly positive function. The discriminator 
                #returns a single value indicating how "real" it thinks it is. 
                #We try to maximise the distance between real and fake.
                #The more negative a value of real_logits, the closer softplus 
                # is to 0 (similar to exponential), this means close to 0 loss.
                discrim_real_loss = tf.math.softplus(-real_logits)
                 
            style_GAN.discriminator_optimiser.apply_gradients(
                    zip(
                        tape.gradient(
                            discrim_real_loss, 
                            style_GAN.discriminator.trainable_variables
                            ), 
                        style_GAN.discriminator.trainable_variables
                        )
                    )  

            #train discriminator on fake images
            with tf.GradientTape() as tape:
                fakes = style_GAN.generator(
                        GANutils.random_generator_inputs(
                            batch_size,
                            style_GAN.latent_dim,
                            style_GAN.start_res,
                            style_GAN.output_res
                            ) 
                        + [batch_generator_base]
                        )
                fake_logits = style_GAN.discriminator(fakes)
                #Should be returning a very low "realness score" so our loss 
                #is directly the softplus sum of output
                discrim_fake_loss = tf.math.softplus(fake_logits) 
            
            style_GAN.discriminator_optimiser.apply_gradients(
                    zip(
                        tape.gradient(
                            discrim_fake_loss, 
                            style_GAN.discriminator.trainable_variables
                            ), 
                        style_GAN.discriminator.trainable_variables
                        )
                    )

            #Train generator. 
            with tf.GradientTape() as tape:
                gen_logits = style_GAN.gan(
                        GANutils.random_generator_inputs(
                            batch_size,
                            style_GAN.latent_dim,
                            style_GAN.start_res,
                            style_GAN.output_res
                            ) 
                        + [batch_generator_base]
                        )
                #We desire the generator to learn weights that make it output 
                #something that results in a 'real' result from the linked 
                #discriminator following immediately in the pipeline
                gen_loss =  tf.math.softplus(-gen_logits) 
             
            style_GAN.generator_optimiser.apply_gradients(
                    zip(
                        tape.gradient(
                            gen_loss, 
                            style_GAN.generator.trainable_variables
                            ), 
                        style_GAN.generator.trainable_variables
                        )
                    )

            #compute the average loss per batch
            metrics_to_store = list(map(
                    lambda x: tf.math.reduce_mean(x).numpy(),
                    [discrim_real_loss, discrim_fake_loss, gen_loss]
                    ))
            for m in range(len(modules.StyleGAN.METRICS)):
                epoch_metrics[modules.StyleGAN.METRICS[m]].append(
                        metrics_to_store[m])
            print("{0}: {3}, {1}: {4}, {2}: {5}".format(
                    *(modules.StyleGAN.METRICS + metrics_to_store) ))

        style_GAN.epochs_trained += 1
        GANutils.save_training_history(epoch_metrics,training_history_location)
        
        #Save image samples if appropriate
        if image_sample_output is not None:
            if not os.path.exists(image_sample_output):
                os.makedirs(image_sample_output)

            samples = style_GAN(GANutils.random_generator_inputs(
                    image_sample_count,
                    style_GAN.latent_dim,
                    style_GAN.start_res,
                    style_GAN.output_res
                    )) #makes use of __call__ defined in styleGAN
            
            sample_directory = image_sample_output + \
                    "epoch_{}".format(style_GAN.epochs_trained)
            
            GANutils.make_fresh_folder(sample_directory)
            for s,sample in enumerate(samples):
                GANutils.create_image(
                        GANutils.denormalise(sample, style_GAN.get_mean()), 
                        sample_directory+"/{}".format(s+1)
                        )

        #Save model if appropriate
        if model_output is not None:
            GANutils.make_fresh_folder(model_output)
            style_GAN.save_model(model_output)


def train(
        model: str = "model/",
        image_source: str = "images/", 
        epochs: int = 10
        ) -> None:
    """
    Conduct a specified number of epochs of training on a given StyleGAN model.
    If model is set to None, then a new styleGAN is instantiated and saved to a 
    default location (model/) upon completion of training. The training paradigm
    employed is described in the fit method employed.

    After training epochs have concluded, a graph of the model's training 
    history is produced. Provided history.csv is present and contains the 
    training history of the specified model's previous training epochs, the 
    generated plot will cover the model's entire training history, from its 
    initialisation forward.

    Args:
        model (str, optional): Folder containing the styleGAN model to train. 
        Defaults to "model/". image_source (str, optional): Folder containing 
        training images. Defaults to "images/". epochs (int, optional): Number 
        of epochs to train the model for. Precondition: positive. Defaults to 10
    """

    #Constant training parameters (Configured for local training using RTX2070)
    BATCH_SIZE = 64
    TRAINING_HISTORY_FILE = "history.csv"
    IMAGE_SAMPLE_COUNT = 5
    IMAGE_SAMPLE_FOLDER = "output/"

    #Note this will be ignored by dataloader if an image cache exists
    COMPRESSION_SIZE = 32 
    
    GENERATOR_INIT_SIZE = 4
    LATENT_DIM = 512

    DEFAULT_MODEL_LOC = "model/"
    HISTORY_PLOT_FILE = "training_loss.png"

    data_loader = dataset.OASIS_loader(image_source, COMPRESSION_SIZE)
    #if model = None use provided constants to generate new StyleGAN
    style_GAN = modules.StyleGAN(
            COMPRESSION_SIZE,
            GENERATOR_INIT_SIZE,
            LATENT_DIM,
            model) 

    #If new model required, store it at default output
    if model == None:
        model = DEFAULT_MODEL_LOC

    fit(
            style_GAN, 
            data_loader, 
            batch_size = BATCH_SIZE, 
            epochs = epochs, 
            training_history_location = TRAINING_HISTORY_FILE, 
            image_sample_count = IMAGE_SAMPLE_COUNT, 
            image_sample_output = IMAGE_SAMPLE_FOLDER, 
            model_output = model
        )

    #Will show plot and also save to disk. Note that by design the history is 
    #appended to, so previous runs of the same model (that is the complete
    #training history) will be plotted
    GANutils.plot_training(
            GANutils.load_training_history(TRAINING_HISTORY_FILE),
            HISTORY_PLOT_FILE, style_GAN.epochs_trained
            )

