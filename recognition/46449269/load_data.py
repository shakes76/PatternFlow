# -*- coding: utf-8 -*-
"""load_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W47y2tM0qQx0pPewZRwx7SKggG7bd4SS
"""

import os
import glob
import sklearn as sk
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import layers, models, Input, Model
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras import backend as K
from IPython.display import clear_output

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

from google.colab import drive
drive.mount('/content/drive')

MASK_PATH = '/content/drive/MyDrive/ISIC2018_Task1_Training_GroundTruth_x2/*.png'
IMAGE_PATH = '/content/drive/MyDrive/ISIC2018_Task1-2_Training_Input_x2/*.jpg'

# Update image dimensions for model
img_height = 256
img_width = 256

def load_data():
  """
  Load and splits the dataset for training, testing and validation.
  Return shuffled tf.data.Dataset objects for train, test and validation datasets.
  """
  images = sorted(glob.glob(IMAGE_PATH))
  masks = sorted(glob.glob(MASK_PATH))

  #Â Split dataset (60% for training, 20% for testing and 20% for validation).
  X_train, X_test, y_train, y_test = train_test_split(images, masks, test_size = 0.2, random_state = 1)
  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 1)

  df_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))
  df_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))
  df_val = tf.data.Dataset.from_tensor_slices((X_val, y_val))

  return df_train.shuffle(len(X_train)), df_test.shuffle(len(X_test)), df_val.shuffle(len(X_val))

df_train, df_test, df_val = load_data()

len(df_train),len(df_test),len(df_val)

def decode_image(path):
  """
  Decodes a .jpeg image. Outputs grayscale image with standardised
  dimension (256 x 192) and normalised pixel values.
  """
  img = tf.io.read_file(path)
  img = tf.image.decode_jpeg(img, channels = 1)
  img = tf.image.resize(img, [img_height, img_width])
  img = tf.cast(img, tf.float32) / 255.0
  return img

def decode_mask(path):
  """
  Decodes a .jpeg image. Outputs grayscale image with standardised
  dimension (256 x 192) and normalised pixel values.
  """
  img = tf.io.read_file(path)
  img = tf.image.decode_png(img, channels = 1)
  img = tf.image.resize(img, [img_height, img_width])
  img = tf.cast(img, tf.float32) / 255.0

  # Round pixel values to be strictly 0 or 1.
  img = tf.math.round(img)
  return img

def process_path(image_path, mask_path):
  """
  Map function for datasets. Decodes images and masks, and reshapes
  dataset tensors for updated image dimensions.
  """
  image = decode_image(image_path)
  mask = decode_mask(mask_path)
  image = tf.reshape(image, (img_height, img_width, 1))
  mask = tf.reshape(mask, (img_height, img_width, 1))
  return image, mask

df_train = df_train.map(process_path)
df_test = df_test.map(process_path)

df_test

df_val = df_val.map(process_path)

def improved_unet(input_size):
  """
  build improved UNET model
  """

  #Input
  inputs = Input(input_size)

  #encoder
  conv1 = layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu")(inputs)
  conv1 = layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu")(conv1)
  p1 = layers.MaxPool2D(pool_size=(2,2))(conv1)

  conv2 = layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu")(p1)
  conv2 = layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu")(conv2)
  p2 = layers.MaxPool2D(pool_size=(2,2))(conv2)

  conv3 = layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu")(p2)
  conv3 = layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu")(conv3)
  p3 = layers.MaxPool2D(pool_size=(2,2))(conv3)

  conv4 = layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu")(p3)
  conv4 = layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu")(conv4)
  p4 = layers.MaxPool2D(pool_size=(2,2))(conv4)

  conv5 = layers.Conv2D(filters=1024, kernel_size=3, padding="same", activation="relu")(p4)
  conv5 = layers.Conv2D(filters=1024, kernel_size=3, padding="same", activation="relu")(conv5)
  drop = layers.Dropout(0.5)(conv5)

  #decoder
  ups6 = layers.Conv2DTranspose(filters=512, kernel_size=3, strides=(2,2), padding="same")(conv5)
  conc6 = layers.concatenate([conv4, ups6], axis=3)
  conv6 = layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu")(conc6)
  conv6 = layers.Conv2D(filters=512, kernel_size=3, padding="same", activation="relu")(conv6)

  ups7 = layers.Conv2DTranspose(filters=256, kernel_size=3, strides=(2,2), padding="same")(conv6)
  conc7 = layers.concatenate([conv3, ups7], axis=3)
  conv7 = layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu")(conc7)
  conv7 = layers.Conv2D(filters=256, kernel_size=3, padding="same", activation="relu")(conv7)

  ups8 = layers.Conv2DTranspose(filters=128, kernel_size=3, strides=(2,2), padding="same")(conv7)
  conc8 = layers.concatenate([conv2, ups8], axis=3)
  conv8 = layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu")(conc8)
  conv8 = layers.Conv2D(filters=128, kernel_size=3, padding="same", activation="relu")(conv8)

  ups9 = layers.Conv2DTranspose(filters=64, kernel_size=3, strides=(2,2), padding="same")(conv8)
  conc9 = layers.concatenate([conv1, ups9], axis=3)
  conv9 = layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu")(conc9)
  conv9 = layers.Conv2D(filters=64, kernel_size=3, padding="same", activation="relu")(conv9)

  outputs = layers.Conv2D(filters=1, kernel_size=1, padding="same", activation="sigmoid")(conv9)
  
  model = Model(inputs=inputs, outputs=outputs)

  return model

improved_unet_model = improved_unet(input_size = (img_height, img_width, 1))

# Dice coef
def dice_coef(y_true, y_pred, smooth=1.0):
  """ Function to calculate Dice similarity Coefficient between mask image and the predicted image

      y_true (numpy.array): a numpy array of groundtruth image data
      y_pred (numpy.array): a numpy array of predicted image data
      smooth (float, optional): a number to avoid division by 0
  """   
  y_true_f = K.flatten(y_true)
  y_pred_f = K.flatten(y_pred)
  intersection = K.sum(y_true_f * y_pred_f)
  return (2. * intersection + smooth) / (K.sum(y_true_f*y_true_f) + K.sum(y_pred_f*y_pred_f) + smooth)

def dice_coef_loss(y_true, y_pred):
  """
  Dice similarity Coefficient loss function between mask image and the predicted  image
  """
  return 1-dice_coef(y_true, y_pred)

# Compile the UNET model, introducing the Dice coefficient in metrics.
improved_unet_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy', dice_coef])

def display(display_list):
  """
  Displays a list of images.
  """
  plt.figure(figsize=(20,20))
  for i in range(len(display_list)):
      plt.subplot(1, len(display_list), i+1)
      plt.imshow(display_list[i], cmap='gray')
      plt.axis('off')
  plt.show()

## TRAIN THE MODEL
BATCH_SIZE = 10
NUM_OF_EPOCH = 50
os.makedirs(result_images_dir, exist_ok=True)
history = improved_unet_model.fit(df_train.batch(BATCH_SIZE), 
          validation_data=df_val.batch(BATCH_SIZE), 
          epochs=NUM_OF_EPOCH)
print()
print("FINISHED TRAINING...")
print()

def show_predictions(ds, num = 1):
  """
  Predicts a mask image, and displays the predicted image.
  """
  for image, mask in ds.take(num):
    pred_mask = model.predict(image[tf.newaxis, ...])[0]
    display([tf.squeeze(image), tf.squeeze(mask), tf.squeeze(pred_mask)])

def plot_accuracy():
  """
  plotting of the accuracy curve.
  """
  plt.figure(0)
  plt.plot(history.history['accuracy'], 'seagreen', label='train')
  plt.plot(history.history['val_accuracy'], label = 'validation')
  plt.xlabel('Epoch')
  plt.ylabel('Accuracy')
  plt.legend(loc='lower right')
  plt.title("Training Accuracy vs Validation Accuracy")
  plt.show()

def plot_dice():
  """
  plotting the Dice coefficient curve.
  """
  plt.figure(1)
  plt.plot(history.history['dice_coef'],'gold', label='train')
  plt.plot(history.history['val_dice_coef'],'yellowgreen', label='validation')
  plt.xlabel("Epoch")
  plt.ylabel("Dice Coefficient")
  plt.legend(loc='lower right')
  plt.title("Training Dice Coefficient vs Validation Dice Coefficient")
  plt.show()

def plot_loss():
  """
  plotting the loss curve.
  """
  plt.figure(2)
  plt.plot(history.history['loss'],'orange', label='train')
  plt.plot(history.history['val_loss'],'salmon', label='validation')
  plt.xlabel("Epoch")
  plt.ylabel("Loss")
  plt.legend(loc='lower right')
  plt.title("Training Loss vs Validation Loss")
  plt.show()

plot_accuracy()
plot_dice()
plot_loss()

print("Loss Function: dice similarity coefficient\n")
improved_unet_model.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy', dice_coef])
improved_unet_model.summary()

# evaluate
[loss, accuracy, dsc] = improved_unet_model.evaluate(df_test.batch(BATCH_SIZE), verbose=1)
print("RESULTS FROM THE EVALUATE FUNCTION:")
print("Loss (dice similarity coefficient):", loss)
print("Dice Similarity Coefficient:", dsc)
print("Accuracy (metrics):", accuracy)
print()