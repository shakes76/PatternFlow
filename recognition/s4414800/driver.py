# -*- coding: utf-8 -*-
"""driver.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h807HBPWJ3Ijd_CLYPmadtDOiJz2Ax0e

@author Yin Peng
@email yin.peng@uqconnect.edu.au
"""

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from keras import backend as K
from model.py import *

import cv2
import glob


# The original image size is 511 X3 84, which is scaled down to 256 X 192
IMG_HEIGHT = 256
IMG_WIDTH = 192

"""
Loading the data locally, generate numpy file so that data 
can be easily used by other high-performance compilers.

"""
def getData(path):
    data = []
    # Get all image path
    image_path = glob.glob(path)
    for path in image_path:
        # IMREAD_GRAYSCALE 
        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (IMG_WIDTH,IMG_HEIGHT))
        if img is not None:
            data.append(img)

    return np.array(data)

mask_data = getData("ISIC2018_Task1_Training_GroundTruth_x2/*.png")
input_data = getData("ISIC2018_Task1-2_Training_Input_x2/*.jpg")

# Save the data for loading
np.save("mask_data.npy",mask_data)
np.save("input_data.npy",input_data)

# Colab loading
mask_data = np.load("drive/MyDrive/Colab Notebooks/COMP3710/mask_data.npy")
input_data = np.load("drive/MyDrive/Colab Notebooks/COMP3710/input_data.npy")

IMAGE_HEIGHT = 256
IMAGE_WEIGHT = 192

mask_data = np.expand_dims(mask_data, axis=3)
input_data = np.expand_dims(input_data, axis=3)

# Normalization
mask_data = mask_data / 255.0
input_data = input_data / 255.0

print(mask_data.shape)
print(input_data.shape)

# Split the data 
X_train, X_test, Y_train, Y_test = train_test_split(input_data, mask_data, test_size = 0.2, random_state = 42)
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 42)

# To tf dataset
train_data = tf.data.Dataset.from_tensor_slices((X_train, Y_train))
test_data = tf.data.Dataset.from_tensor_slices((X_test, Y_test))
val_data = tf.data.Dataset.from_tensor_slices((X_val, Y_val))

train_data = train_data.shuffle(len(train_data))
test_data = test_data.shuffle(len(test_data))
val_data = val_data.shuffle(len(val_data))

def display_image(data,num):
  plt.figure(figsize=(10,3*num))
  i = 1
  for X,Y in data.take(num):
    plt.subplot(num, 2, i)
    plt.imshow(tf.reshape(X,[IMAGE_HEIGHT,IMAGE_WEIGHT]), cmap='gray')
    plt.axis('off')
    i += 1
    plt.subplot(num, 2, i)
    # plt.imshow(Y, cmap='gray')
    plt.imshow(tf.reshape(Y,[IMAGE_HEIGHT,IMAGE_WEIGHT]), cmap='gray')
    plt.axis('off')
    i += 1
  plt.show()

display_image(train_data,5)

model = Unet(input_shape = (IMAGE_HEIGHT, IMAGE_WEIGHT, 1))

def dice_coef_loss(y_true, y_pred):
  '''
  Dice loss to minimize. Pass to model as loss during compile statement
  '''
  return 1 - dice_coef(y_true, y_pred)

def dice_coef(y_true, y_pred, smooth=0):
  """
  function to calculate dice similarity
  """
  y_true_f = K.flatten(y_true)
  y_pred_f = K.flatten(y_pred)
  intersection = K.sum(y_true_f * y_pred_f)
  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)


model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = [dice_coef])
# model.compile(optimizer = 'adam', loss = dice_coef_loss, metrics = ["accuracy",dice_coef])
history = model.fit(train_data.batch(10), epochs = 40, validation_data = val_data.batch(10))

def display_prediction(num):
  i = 1
  plt.figure(figsize=(15,3*num))
  for t_x,t_y in test_data.take(num):
    y_predict = model.predict(t_x[tf.newaxis, ...])
    ax = plt.subplot(num, 3, i)
    ax.set_title("Input Image")
    plt.imshow(tf.reshape(t_x,[IMAGE_HEIGHT,IMAGE_WEIGHT]), cmap='gray')
    plt.axis('off')
    i += 1
    ax = plt.subplot(num, 3, i)
    ax.set_title("Mask Image")
    plt.imshow(tf.reshape(t_y,[IMAGE_HEIGHT,IMAGE_WEIGHT]), cmap='gray')
    plt.axis('off')
    i += 1
    ax = plt.subplot(num, 3, i)
    ax.set_title("Predict Image")
    plt.imshow(tf.reshape(y_predict,[IMAGE_HEIGHT,IMAGE_WEIGHT]), cmap='gray')
    plt.axis('off')
    i += 1
  
  plt.show()

display_prediction(5)

y_pred = model.predict(X_test)

def numpy_dice_coef(y_true, y_pred,smooth = 1e-5):
  """
  function to calculate dice similarity by numpy
  """
  y_true_f = y_true.flatten()
  y_pred_f = y_pred.flatten()
  intersection = np.sum(y_true_f * y_pred_f)
  return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

test_dice_coef = []
for pre,test in zip(y_pred,Y_test):
  test_dice_coef.append(numpy_dice_coef(pre,test))
avg_DSC = np.mean(test_dice_coef)
print(f"Average DSC on the test set is:{avg_DSC}")

def plot_similarity():
  """
  Plot the dice similarity score
  """
  plt.figure(1)
  plt.plot(history.history['dice_coef'],'red', label='train')
  plt.plot(history.history['val_dice_coef'],'green', label='validation')
  plt.xlabel("Epoch")
  plt.ylabel("Dice Coefficient")
  plt.title("Dice Coefficient")
  plt.legend(loc='lower right')
  plt.show()

plot_similarity()