# Using Siamese Network To Classify Alzheimer's Disease
### Haolong Du (46272784)

## **Architecture** 
The Siamese Neural Network (SNN) is an artificial neural network that contains two (or more) parallel and identical Convolutional Neural Networks (CNN) which accept distinct inputs and produces embedding for the input. These embeddings are compared to generate a similarity score. The following figure illustrates the architecture of a SNN.

![1_23mikUF3HBJGUqrX7tMKQQ](https://user-images.githubusercontent.com/103046146/196857370-c953cb10-4b42-43e1-b42e-53d398439ee6.png)

For this project, the inputs are images from the ADNI brain dataset.

## **Implimentation**
The CNN in the network consists of 4 convolution layers, with max pooling and batch normalization layers between each convolution layer, the units in the final convolution layer are flattened and maped to a vector by a fully connected layer. The output vectors from the CNN are merged together, and then mapped to a sigmoid output layer.

## **Data preprocessing**
### ***Making pairs***
The original dataset are separated in two folders: train and test, and inside these folders, the data are split into two classes: AD and NC. Note that for SNN, the iput data are 'pairs' of two images and a label [im1, im2, label], where the label is 1 if both image are of the same class, and 0 otherwise. In order to generate these pairs, we first generate datasets that coorespond to classes (train_ad, train_nc, test_ad, test_nc), the validation dataset were generated by split the train datasets by a ratio of 1/5 (20% data gose to validation, and 80% remains as training). \
Now the images are splited into classes, we can then generate pairs by tf.zip, which creats pairs of images [im1, im2]. Then, the labels are assigned to the pairs. Finally, the dataset is shuffled using tf.data.experimental.sample_from_datasets() and batched with batch size of 16.
![Figure_1](https://user-images.githubusercontent.com/103046146/196894876-e7a6aafb-b5a9-4a07-9404-116564fe4eb6.png)

### ***Data augmentation:***
To increase accuracy, data augmentation is also used. The images are randomly rotated, shifted and stretched.

## **Training**
The model is trained for 10 epochs using binary cross entropy as loss function and adam as optimizer. (Note: I was unable to impliment the prograss bar using tqdm, as a remedy, the training loss and accuracy are printed out) The following plots shows the training/validation accuracy. It is clear that the validation accuracy is greater than 80%.\
![Screenshot 2022-10-20 182246](https://user-images.githubusercontent.com/103046146/196896057-cd69a1fa-e55a-4420-b4b8-f09543d9ada3.png)

## **Dependencies**
- Python: 3.9.13
- TensorFlow: 2.6.0
- Matplotlib: 3.5.2

## **Reference**
- G. Koch, R. Zemel, R. Salakhutdinov et al., "Siamese Neural Networks for One-shot Image Recognition"
- Keras tutorial on Siamese network, https://keras.io/examples/vision/siamese_contrastive/
- Tensorflow tutorial on save and load model, https://www.tensorflow.org/tutorials/keras/save_and_load
- Tensorflow tutorial on writing training loop, https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch
  