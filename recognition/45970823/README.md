# Deep Convolutional Generative Adversarial Network (DCGAN) 
## Author: Dream Gonsalves-45970823


##### Pattern Recognition Report 
Task 6 : Create a generative model of the OASIS brain dataset using a [DCGAN](https://arxiv.org/abs/1511.06434) that
has a “reasonably clear image” and a [Structured Similarity (SSIM)](https://en.wikipedia.org/wiki/Structural_similarity) of over 0.6. [Hard Difficulty]


* [Algorithm Description](#Algorithm-Description)<br>
* [Problem Description](#Problem-Description)<br>
* [Tools and Technologies used](#Tools-and-Technologies-used)<br>
* [Executing the code](#Executing-the-code)<br>
* [DCGAN Implementation](#DCGAN-Implementation)<br>
* [DCGAN Evaluation](#DCGAN-Evaluation)<br>
* [References](#References)

### Algorithm Description 

Deep Convolutional Generative Adversarial Network(DCGAN),the main purpose is to produce fake images as similar as possible to real train images. It consists of two main models: Generator and Discriminator. This two models are trained simultaneously by adversarial process. 


![Generator and Discriminator image](https://gluon.mxnet.io/_images/dcgan.png)

#### Generator
Generator generates fake images. The fake images are formed using noise image and a fake image of same size of the real image is generated.The Generator has never seen the real image it just depends on the Discriminator to check if the training process is going in the correct direction. 


#### Discriminator
Discriminator works as a classifier, it classifies the fake images generated by the Generator. The loss function is evaluated and as we go on training the model and increasing the epochs, for the end results an ideal Generator will produce a fake image which the Discriminator will fail to classify correctly that is when we know the model is built accurately. The overall idea is that we need to decrease the generator loss and simultaneously the discriminator loss will go on increasing to ensure the model is built correctly.


![Generator and discriminator working](https://www.tensorflow.org/tutorials/generative/images/gan2.png)















### Problem Description
#### Dataset : OASIS brain dataset
The dataset used is [OASIS brain dataset](https://www.oasis-brains.org/) which includes 9,000 images produced by [Magnetic Resonance Imaging(MRI)](https://www.nibib.nih.gov/science-education/science-topics/magnetic-resonance-imaging-mri) on different individuals. This data is collected for diagnosis of different brain issues or damages. Our aim is to train the [DCGAN](https://arxiv.org/abs/1511.06434) model on the OASIS brain images and try to generate fake images similar to the train data and evaluate it using the metrics [Structured Similarity (SSIM)](https://en.wikipedia.org/wiki/Structural_similarity),we will try to achieve SSIM over 0.6.

The fake data generation is useful for studying the diagnosis of the brain data, getting such a huge dataset for medical image analysis is very challenging. GAN solves the limited dataset problem. GAN can provide this data easily so that the medical professionals can validate and study more about the human brain. 



#### Tools and Technologies used
Some of the main libraries used for the implementation of the problem are:

[Opencv-python](https://pypi.org/project/opencv-python/) is used to load the OASIS brian dataset in a proper format to use make optimised used of the dataset to train the models.

The whole algorithm is build in [Tensorflow](https://www.tensorflow.org/) an open source Machine learning platform. 

[Keras](https://keras.io/) is used on the top of tensorflow for building the deep learning model for DCGAN.

For visualisations [matplotlib](https://matplotlib.org/) is used.It is a great visualization tool for python.


#### Executing the code

The src consists of dcgan.py, main.py, main.ipynb 

dcgan.py:Consists of all the generator and discriminator functions required to run the main.py file.

main.py: Is the main script to run the algorithm (run this to execute the algorithm)

main.ipynb: Jupyter Notebook visualisation file to show the process in the main.py

### DCGAN Implementation

#### OASIS brain Data
Data Preprocessing is done before training the models, The original image is changed to Gray scale ([RGB[A] to Gray:Y←0.299⋅R+0.587⋅G+0.114⋅B](https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html#color_convert_rgb_gray)) and reshaped to 128x128 size for faster training.
Example: Original image, Gray scale, Resized image to 128x128


![imagedata](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/data_preprocessing.PNG?raw=True)


#### Generator

The Generator model is squential model built using [Keras Sequential API](https://www.tensorflow.org/guide/keras/sequential_model#sequential_model). 
The generator uses [tf.keras.layers.Conv2DTranspose](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose) (upsampling) layers, [Batch normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization) is done on each layer and [Leaky RelU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU) is used as the activation function, the layers and parameters details are as below:

![generator](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/generator_summary.PNG?raw=True)

![Noise](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/fake_image.PNG?raw=True)


The image above is the initial Fake image generated using random noise to train the model. The size of the image is set as 128x128 same as the input train image size. The data is then send to the discriminator to classify.

#### Discriminator
The Discriminator is built using [Convolutional Neural Network](https://www.tensorflow.org/tutorials/images/cnn) to classify the fake images generated by the Generator model.The layers and parameters details are as below:


![Discriminator](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/discriminator_summary.PNG?raw=True)

The discriminator is [binary classifier](https://en.wikipedia.org/wiki/Binary_classification#:~:text=Binary%20classification%20is%20the%20task,basis%20of%20a%20classification%20rule.), it predicts positive value(1) for Real image and negative value(0) for Fake image.

Reference:[DCGAN Implementation](https://www.tensorflow.org/tutorials/generative/dcgan)

#### Training the model
The training of the model begins with providing the generator a random seed as input. That seed is used to generate an noise image. The discriminator is then called to classify the fake(Generator images) and real(train dataset images). The loss function is used to evaluate the generator and discriminator model, and the gradients are used to update the generator and discriminator to lead the model to lesser generator loss and greater discriminator loss.Shown below are the fake images generated during training throughout the epochs untill ssim>0.6 is reached.

![Training](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/dcgan.gif?raw=True)



### DCGAN Evaluation
To evaluate the model we will check the loss of the Discriminator and the Generator.

#### Discriminator loss
This method checks how well the discriminator is able to classify between real images and fake images. It compares the discriminator's predictions on real images to an array of 1s, and the discriminator's predictions on fake (generated) images to an array of 0s.

#### Generator loss
The generator's loss is to evaluate if the generator was able to trick the discriminator. If the generator is performing well, the discriminator will classify the fake images as real (or 1). 

On training the models, as we go on increasing the iterations or the epochs the generator loss decreases and the discriminator loss increases, this means the model is accurate. 


![Loss](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/loss_graph.PNG?raw=True)

#### SSIM
For this model evaluation we will be using the metrics [Structured Similarity (SSIM)](https://en.wikipedia.org/wiki/Structural_similarity). SSIM over 0.6 is required, the model will stop training when the SSIM > 0.6 is reached. The image below shows the SSIM value plot thoughout the number of epoch required to train the model to get SSIM >0.6


![SSIM](https://github.com/dreamgonsalves/PatternFlow/blob/topic-recognition/recognition/45970823/Images/ssim.PNG?raw=True)



### References
* https://www.oasis-brains.org/ <br>
* https://pypi.org/project/opencv-python/<br>
* https://www.tensorflow.org/<br>
* https://keras.io/<br>
* https://matplotlib.org/<br>
* https://arxiv.org/abs/1511.06434<br>
* https://www.tensorflow.org/tutorials/generative/dcgan<br>
* https://en.wikipedia.org/wiki/Structural_similarity<br>
* https://gluon.mxnet.io/chapter14_generative-adversarial-networks/dcgan.html

