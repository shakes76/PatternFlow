{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"styleGAN.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1MGdz7dTs_VJ5__my50nr_cxgBhH72Vgm","authorship_tag":"ABX9TyPcXJgzwqZUXyEynlSMMTp4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"hHzcLRkr6BIE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635650332885,"user_tz":-600,"elapsed":883,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"d092b1f5-86ef-4882-9a28-8769145d72a9"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Oct 31 03:18:51 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.29.05    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    41W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"EgruSdeh6Dl7"},"source":["!unzip 'drive/MyDrive/COMP3710/OASIS.zip' -d 'sample_data/data/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SHZFAdKXLPrg"},"source":["import numpy as np \n","import matplotlib.pyplot as plt \n","import torch \n","import torch.nn as nn \n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader,SubsetRandomSampler\n","from torchvision.utils import make_grid\n","from torchvision import datasets, transforms\n","import pickle as pkl\n","from tqdm import tqdm\n","from PIL import Image\n","#torch.manual_seed(777)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O83d9dbYZiCY"},"source":["\"\"\"\n","learned from:\n","https://github.com/lernapparat/lernapparat/blob/master/style_gan/pytorch_style_gan_test_discriminator.ipynb\n","https://github.com/aladdinpersson/Machine-Learning-Collection/tree/master/ML/Pytorch/GANs/StyleGAN\n","https://github.com/rosinality/style-based-gan-pytorch\n","https://github.com/caffeinism/StyleGAN-pytorch\n","https://github.com/facebookresearch/pytorch_GAN_zoo/tree/b75dee40918caabb4fe7ec561522717bf096a8cb/models/networks\n","\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRi5GeWQE1Tl"},"source":["class WScaledConv(nn.Module):\n","  \"\"\"\n","  Weight scaled conv2d,\n","  input: b *in_features *H *W\n","  output: b *out_features *H *W (weight scaled)\n","  \"\"\"\n","  def __init__(self, ins, outs, k_size=3, stride=1, padding=1):\n","    super().__init__()\n","    self.k_size = k_size\n","    self.stride = stride\n","    self.padding = padding\n","\n","    self.scale = (2/(k_size*k_size*ins))**(1/2)\n","    self.w = torch.nn.Parameter(torch.randn(outs, ins, k_size, k_size))\n","    self.bias = torch.nn.Parameter(torch.zeros(outs))\n","  def forward(self, x):\n","    return F.conv2d(x, self.w*self.scale, self.bias, stride=self.stride, padding=self.padding)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6NXAWyi-zb9"},"source":["class WScaledLinear(nn.Module): #output shape tested\n","  \"\"\"\n","  Weight scaled Linear,\n","  input: b *in_channels *H *W\n","  output: b *out_channels *H *W (weight scaled)\n","  \"\"\"\n","  def __init__(self, ins=512, outs=512, lr_mul=1.0):\n","    super().__init__()\n","    self.ins=ins\n","    self.outs=outs\n","    self.lr_mul=lr_mul\n","\n","    self.scale=((2/ins)**(1/2))*self.lr_mul\n","    self.w=torch.nn.Parameter(torch.randn(outs, ins))\n","    self.bias=torch.nn.Parameter(torch.zeros(outs))\n","  def forward(self, x):\n","    return F.linear(x, self.w*self.scale, self.bias)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ew0zoafQOpB8"},"source":["class PixelNorm(nn.Module): #embedding into MappingNet, not used anymore\n","  \"\"\"\n","  Pixel normalization,\n","  input: b *z_dimension\n","  output: b *z_dimension (normalized)\n","  \"\"\"\n","  def __init__(self, epsilon=1e-8):\n","    super().__init__()\n","    self.epsilon=epsilon\n","  def forward(self, x):\n","    #normalize by avearage value across dimension 1 plus epsilon\n","    x_=(x*x).mean(dim=1,keepdim=True)+self.epsilon\n","    return x/(x_**0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hnbWGfFdR5xV"},"source":["class MappingNet(nn.Module):\n","  \"\"\"\n","  8-dense-layers MappingNet, projecting latent z(ins) to w(outs)\n","  PixelNorm is merged into here\n","  input: b *z_dimension\n","  output: b *w_dimension\n","  \"\"\"\n","  def __init__(self,ins=512,outs=512,n_layers=8):\n","    super().__init__()\n","    self.mapping=nn.ModuleList()\n","    self.mapping.append(WScaledLinear(ins,outs,lr_mul=0.01))\n","    for i in range(n_layers-1):\n","      self.mapping.append(nn.ReLU())\n","      self.mapping.append(WScaledLinear(outs,outs,lr_mul=0.01))\n","  def forward(self, x):\n","    #PixelNorm\n","    x_=(x*x).mean(dim=1,keepdim=True)+1e-8 #epsilon=1e-8\n","    x=x/(x_**0.5)\n","    #8 dense layers\n","    for model in self.mapping:\n","      x=model(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NQmu2L12S4Kh"},"source":["class AdaIN(nn.Module): \n","  \"\"\"\n","  Adaptive Instance Norm,\n","  latent w required for using \"style\", use WScaledLinear(ins(w), outs(c))\n","  where w is the #-output of the mapping net and c is the #-output channels of the previous layer\n","  input: w, b *w_dim, and x, b *in_features *H *W\n","  output: x, b *out_features *H *W (multiplied by and added with style)\n","  \"\"\"\n","  def __init__(self, ins=512, outs=512):\n","    super().__init__()\n","    self.insnorm=nn.InstanceNorm2d(outs,affine=False)\n","    self.style_wfactor=WScaledLinear(ins,outs)\n","    self.style_bias=WScaledLinear(ins,outs)\n","  def forward(self, x, w):\n","    #latent w is the output of the mapping net\n","    #x is the output of the previous layer\n","    size=x.size()\n","    style_wf=self.style_wfactor(w).view(size[0],size[1],1,1)\n","    style_b=self.style_bias(w).view(size[0],size[1],1,1)\n","    return x*style_wf+style_b\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6SdSwOwpveo"},"source":["class Gblock(nn.Module):\n","  \"\"\"\n","  Generative block,\n","  each block contains one upscale layer and two conv layers (except for the initial block)\n","  input: w, b *w_dim, and x, b *in_features *H *W\n","  output: x, b *out_features *H *W \n","  \"\"\"\n","  def __init__(self, initial=False, ins=512, outs=512, b_size=32,device='cuda'):\n","    super().__init__()\n","    self.initial=initial\n","    self.ins=ins\n","    self.outs=outs\n","    self.b_size=b_size\n","    self.device=device\n","    \n","    if self.initial:\n","      self.const=nn.Parameter(torch.ones((b_size,ins,4,4)))\n","      self.noise_scaler1=((2/(4*4*self.ins))**(1/2))\n","    else:\n","      self.conv1=WScaledConv(ins=self.ins,outs=self.outs)\n","      self.noise_scaler1=((2/(3*3*self.ins))**(1/2))\n","    self.noise_w1=nn.Parameter(torch.zeros(1, self.outs, 1, 1))\n","    self.ada1=AdaIN(outs=outs)\n","\n","    self.conv2=WScaledConv(ins=self.outs,outs=self.outs)\n","    self.noise_scaler2=((2/(3*3*self.outs))**(1/2))\n","    self.noise_w2=nn.Parameter(torch.zeros(1, self.outs, 1, 1))\n","    self.ada2=AdaIN(outs=outs)\n","    self.lkrelu=nn.LeakyReLU(0.2,inplace=True)\n","    self.upscale_conv=WScaledConv(ins=self.ins,outs=self.ins,k_size=1,padding=0)\n","  def upscale(self, x):\n","    return self.upscale_conv(F.interpolate(x,scale_factor=2))\n","\n","  def forward(self, x, w):\n","    if self.initial:\n","      x=self.const\n","      #constant\n","      #or one dense layer for random inputs\n","    else:\n","      x=self.upscale(x)#upscale\n","      x=self.conv1(x)#conv1(WScaled)\n","      x=self.lkrelu(x)\n","    size=x.size()\n","    noise1=torch.randn((size[0], 1, size[2], size[3]),device=self.device)*self.noise_scaler1\n","    x=x+self.noise_w1*noise1#add noise\n","    x=self.ada1(x,w)#AdaIn\n","\n","    x=self.conv2(x)\n","    x=self.lkrelu(x)\n","    noise2=torch.randn((size[0], 1, size[2], size[3]),device=self.device)*self.noise_scaler2\n","    x=x+self.noise_w2*noise2#add noise\n","    x=self.ada2(x,w)#AdaIn\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kIfvb6gvx-sh","executionInfo":{"status":"ok","timestamp":1634452144851,"user_tz":-600,"elapsed":2360,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"70bcde6b-c5f8-467a-92fe-d162bd01de63"},"source":["noise=torch.randn(32,512)\n","mp=MappingNet()\n","noise=mp(noise)\n","Gblk1=Gblock(initial=True)\n","Gblk2=Gblock(ins=512,outs=256)\n","Gblk3=Gblock(ins=256,outs=128)\n","Gblk4=Gblock(ins=128,outs=64)\n","Gblk5=Gblock(ins=64,outs=32)\n","Gblk6=Gblock(ins=32,outs=16)\n","Gblk7=Gblock(ins=16,outs=8)\n","a=Gblk1(x=None,w=noise)\n","print(a.shape)\n","b=Gblk2(x=a,w=noise)\n","print(b.shape)\n","c=Gblk3(x=b,w=noise)\n","print(c.shape)\n","d=Gblk4(x=c,w=noise)\n","print(d.shape)\n","e=Gblk5(x=d,w=noise)\n","print(e.shape)\n","f=Gblk6(x=e,w=noise)\n","print(f.shape)\n","g=Gblk7(x=f,w=noise)\n","print(g.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 512, 4, 4])\n","torch.Size([32, 256, 8, 8])\n","torch.Size([32, 128, 16, 16])\n","torch.Size([32, 64, 32, 32])\n","torch.Size([32, 32, 64, 64])\n","torch.Size([32, 16, 128, 128])\n","torch.Size([32, 8, 256, 256])\n"]}]},{"cell_type":"code","metadata":{"id":"gLcMeFlRpZck"},"source":["class Gnet(nn.Module):\n","  \"\"\"\n","  Generator,\n","  input: noise, b *num_features, 32*512\n","  output: image, b *num_channels *H *W, 32*1*256*256\n","  #-blocks = 7 [0 1 2 3 4 5 6]\n","  #-features= [ 512), 512, 256, 128, 64, 32, 16, 8 ]\n","  img_size = [ 4const), 4, 8, 16, 32, 64, 128, 256 ]\n","  \"\"\"\n","  def __init__(self, b_size=32, nc=1):\n","    super().__init__()\n","    n_features=[512, 256, 128, 64, 32, 16, 8]\n","    self.n_layers=len(n_features)\n","    self.steps=0\n","    self.b_size=b_size\n","\n","    self.alpha=1.0\n","    self.z2w=MappingNet()\n","    self.Gblocks=nn.ModuleList()\n","    self.Gblocks.append(Gblock(initial=True))\n","    for i in range(self.n_layers-1):\n","      self.Gblocks.append(Gblock(ins=n_features[i],outs=n_features[i+1]))\n","    \n","    self.toImg=nn.ModuleList()\n","    for i in range(self.n_layers):\n","      self.toImg.append(WScaledConv(ins=n_features[i],outs=nc,k_size=1,stride=1,padding=0))\n","    self.upscale_conv=nn.ModuleList()\n","    for i in range(self.n_layers-1):\n","      self.upscale_conv.append(WScaledConv(ins=1,outs=nc,k_size=1,stride=1,padding=0))\n","  def fadeIn(self, x_cur=None, x_pre=None):\n","    last=self.toImg[self.steps](x_cur)\n","    if self.alpha>0:\n","      Sndlast=self.toImg[self.steps-1](x_pre)\n","      Sndlast=F.interpolate(Sndlast,scale_factor=2)\n","      Sndlast=self.upscale_conv[self.steps-1](Sndlast)\n","      return self.alpha*Sndlast+(1-self.alpha)*last\n","    else:\n","      return last\n","  def forward(self, noise, alpha, steps):\n","    self.steps=steps\n","    self.alpha=alpha\n","    w=self.z2w(noise)\n","    if self.steps==0:\n","      return self.toImg[0](self.Gblocks[0](x=None,w=w))\n","    else:\n","      for i in range(0,self.steps+1):\n","        if i==0:\n","          x=self.Gblocks[0](x=None,w=w)\n","        else:\n","          x=self.Gblocks[i](x,w)\n","\n","        if i==self.steps-1:\n","          x_=x \n","      return self.fadeIn(x_cur=x, x_pre=x_)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9QPv9K7QSR23","executionInfo":{"status":"ok","timestamp":1634563211831,"user_tz":-600,"elapsed":2920,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"69beb8f8-173a-4614-ee24-119aeb487894"},"source":["G=Gnet()\n","noise=torch.randn(32,512)\n","a=G(noise,alpha=0.5,steps=6)\n","a.shape"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0 torch.Size([32, 512, 4, 4])\n","1 torch.Size([32, 256, 8, 8])\n","2 torch.Size([32, 128, 16, 16])\n","3 torch.Size([32, 64, 32, 32])\n","4 torch.Size([32, 32, 64, 64])\n","5 torch.Size([32, 16, 128, 128])\n","6 torch.Size([32, 8, 256, 256])\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1, 256, 256])"]},"metadata":{},"execution_count":81}]},{"cell_type":"code","metadata":{"id":"jq8QLS3sY7ln"},"source":["class Dblock(nn.Module):\n","  \"\"\"\n","  input: b*n_features*H*W\n","  output: b*(n_features/2)*H*W, for the initial(last) layer is b*1(classification result)\n","  minibatch_std not implemented yet\n","  \"\"\"\n","  def __init__(self, initial=False, ins=512, outs=512, b_size=32):\n","    super().__init__()\n","    self.initial=initial\n","    self.ins=ins if not initial else ins+1\n","    self.outs=outs\n","    self.b_size=b_size\n","    self.conv1=WScaledConv(self.ins,self.outs,k_size=3)\n","    if self.initial:\n","      self.conv2=WScaledConv(self.outs,self.outs,k_size=4,padding=0)\n","      self.conv3=WScaledConv(self.outs,1,k_size=1,padding=0)\n","    else:\n","      self.conv2=WScaledConv(self.outs,self.outs,k_size=3,padding=1)\n","      self.downscale=nn.AvgPool2d(kernel_size=2,stride=2)\n","    self.lkrelu=nn.LeakyReLU(0.2,inplace=True)\n","  def minibatch_std(self, x):\n","    size=x.size()\n","    batch_std=torch.std(x,dim=0)\n","    mean_std=batch_std.mean()\n","    return torch.cat([x,mean_std.repeat(size[0],1,size[2],size[3])],dim=1)\n","  def forward(self, x):\n","    if self.initial:\n","      x=self.minibatch_std(x)\n","      \n","    x=self.lkrelu(self.conv1(x))\n","    x=self.lkrelu(self.conv2(x))\n","    if self.initial:\n","      x=self.conv3(x).view(self.b_size,-1)\n","    else:\n","      x=self.downscale(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bRYtmHn2z2XC","executionInfo":{"status":"ok","timestamp":1634635566370,"user_tz":-600,"elapsed":2151,"user":{"displayName":"Joe Huang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16493752761663840459"}},"outputId":"3e43e7ef-eeb9-471b-ace9-0cf14a45e806"},"source":["n=torch.randn(32,8,256,256)\n","n_features=[8, 16, 32, 64, 128, 256, 512]\n","k=nn.ModuleList()\n","for i in range(7-1):\n","  k.append(Dblock(ins=n_features[i],outs=n_features[i+1]))\n","k.append(Dblock(initial=True))\n","print(n.shape)\n","for m in k:\n","  n=m(n)\n","  print(n.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 8, 256, 256])\n","torch.Size([32, 16, 128, 128])\n","torch.Size([32, 32, 64, 64])\n","torch.Size([32, 64, 32, 32])\n","torch.Size([32, 128, 16, 16])\n","torch.Size([32, 256, 8, 8])\n","torch.Size([32, 512, 4, 4])\n","torch.Size([32, 1])\n"]}]},{"cell_type":"code","metadata":{"id":"cgnM1Ko0Tfex"},"source":["class Dnet(nn.Module):\n","  \"\"\"\n","  Discriminator,\n","  input: image b*1*H*W\n","  output: classification result b*1\n","  \"\"\"\n","  def __init__(self, b_size=32, nc=1):\n","    super().__init__()\n","    n_features=[8, 16, 32, 64, 128, 256, 512]\n","    self.n_layers=len(n_features)\n","    self.steps=0\n","    self.b_size=b_size\n","\n","    self.alpha=1.0\n","    self.alpha_decay=2.26e-4\n","    self.cur_sacle=0\n","    \n","    self.Dblocks=nn.ModuleList()\n","    for i in range(self.n_layers-1):\n","      self.Dblocks.append(Dblock(ins=n_features[i],outs=n_features[i+1]))\n","    self.Dblocks.append(Dblock(initial=True))\n","\n","    self.fromImg=nn.ModuleList()\n","    for i in range(self.n_layers):\n","      self.fromImg.append(WScaledConv(ins=nc,outs=n_features[i],k_size=1,stride=1,padding=0))\n","    \n","  def fadeIn(self, x):\n","    t=self.n_layers-self.steps-1\n","    last=self.Dblocks[t](self.fromImg[t](x))\n","    if self.alpha>0:\n","      Sndlast=self.fromImg[t+1](nn.AvgPool2d(kernel_size=2,stride=2)(x))\n","      return self.alpha*Sndlast+(1-self.alpha)*last\n","    else:\n","      return last\n","\n","  def forward(self, x, alpha, steps):\n","    self.steps=steps\n","    self.alpha=alpha\n","    if self.steps==0:\n","      return self.Dblocks[-1](self.fromImg[-1](x))\n","    else:\n","      t=self.n_layers-self.steps-1\n","      x=self.fadeIn(x)\n","      for i in range(t+1,self.n_layers):\n","        x=self.Dblocks[i](x)\n","      return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJHeCFcXJ2bE"},"source":["n=torch.randn(32,1,256,256)\n","a=Dnet()\n","t=a(n,0.5,6)\n","print(t.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r7b5bLRbRKpj"},"source":["class Trainer():\n","  \"\"\"\n","  styleGAN trainer,\n","  give dataroot(dir of image data) and sample_path(dir for saving results),\n","  then start training with training_loop(),\n","  prog_epochs define the epochs for each steps, from 0 to 6\n","  save_only set the number of output images to a fixed number during training\n","  \"\"\"\n","  def __init__(self, b_size=32, z_dim=512, nc=1, dataroot='sample_data/data',sample_path='drive/MyDrive/training_results_style/', device='cuda', prog_epochs=[10,10,10,10,10,10,10],save_only=9):\n","    self.b_size=b_size\n","    self.z_dim=z_dim\n","    self.nc=nc\n","    self.dataroot=dataroot\n","    self.sample_path=sample_path\n","    self.model_path=sample_path\n","    self.device=device\n","    self.prog_epochs=prog_epochs\n","    self.save_only=save_only\n","\n","    self.gif=[]\n","    self.cur_epoch=0\n","    self.img_size=4\n","    self.dataset_length=None\n","    self.dataloader=None\n","    self.step=0\n","    self.alpha=0.999\n","    self.fixed_noise1,self.fixed_noise2=torch.randn((self.b_size, self.z_dim)).to(device),torch.randn((self.b_size, self.z_dim)).to(device)    \n","    self.lr=0.001\n","    self.G,self.D=Gnet().to(self.device),Dnet().to(self.device)\n","    self.scaler_G,self.scaler_D=torch.cuda.amp.GradScaler(),torch.cuda.amp.GradScaler()\n","    self.opt_G = optim.Adam([{\"params\": [param for name, param in self.G.named_parameters() if \"map\" in name],\"lr\":self.lr*0.01},\n","                {\"params\": [param for name, param in self.G.named_parameters() if \"map\" not in name],\"lr\":self.lr}], betas=(0.0, 0.99))\n","    self.opt_D = optim.Adam(self.D.parameters(), lr=self.lr, betas=(0.0, 0.99))\n","    self.loss_G,self.loss_D=0,0\n","    self.losses=[[],[]]\n","\n","  def get_loader(self):\n","    #load data and resize the image depending on current step\n","    transform = transforms.Compose([transforms.Resize((self.img_size, self.img_size)), transforms.ToTensor(),transforms.RandomVerticalFlip(),\n","                    transforms.Grayscale(1), transforms.Normalize(0.5,0.5)])\n","    dataset = datasets.ImageFolder(root=self.dataroot, transform=transform)\n","    self.dataloader = DataLoader(dataset, batch_size=self.b_size,\n","            shuffle=True, num_workers=0, pin_memory=True)\n","    self.dataset_length=len(dataset)\n","  def train_D(self,real):\n","    #train D for one iteration\n","    noise = torch.randn(self.b_size, self.z_dim).to(self.device)\n","    self.opt_D.zero_grad()\n","    with torch.cuda.amp.autocast():\n","      fake = self.G(noise, self.alpha, self.step)\n","      D_real = self.D(real, self.alpha, self.step)\n","      D_fake = self.D(fake.detach(), self.alpha, self.step)\n","      loss_D1=F.softplus(D_fake)\n","      loss_D2=F.softplus(-D_real)\n","      loss_Dall=torch.mean(loss_D1+loss_D2)\n","      \n","    self.loss_D+=loss_Dall.item()\n","    self.scaler_D.scale(loss_Dall).backward()\n","    self.scaler_D.step(self.opt_D)\n","    self.scaler_D.update()\n","  def train_G(self):\n","    #train G for one iteration\n","    noise = torch.randn(self.b_size, self.z_dim).to(self.device)\n","    self.opt_G.zero_grad()       \n","    with torch.cuda.amp.autocast():\n","      fake = self.G(noise, self.alpha, self.step)\n","      D_fake = self.D(fake, self.alpha, self.step)       \n","      loss_G=torch.mean(F.softplus(-D_fake))\n","\n","    self.loss_G+=loss_G.item()\n","    self.scaler_G.scale(loss_G).backward()\n","    self.scaler_G.step(self.opt_G)\n","    self.scaler_G.update()\n","  \n","  def train_one_epoch(self):\n","    #train one epoch\n","    iterations=tqdm(self.dataloader)\n","    samples_save=[]\n","    for i,[real,_] in enumerate(iterations):\n","      real = real.to(self.device)\n","      #Train D\n","      self.train_D(real)\n","      #Train G  \n","      self.train_G()      \n","      #Update alpha\n","      self.alpha-=self.b_size/((self.prog_epochs[self.step]*0.5)*self.dataset_length)\n","      self.alpha=max(self.alpha,0)\n","    #record losses\n","    self.losses[0].append(self.loss_G/len(iterations))\n","    self.losses[1].append(self.loss_D/len(iterations))\n","    self.loss_G,self.loss_D=0,0\n","      \n","  def save_samples_pkl(self):\n","    #save training images as .pkl, not used anymore\n","    with torch.no_grad():\n","      fixed_fakes=(self.G(self.fixed_noise1, self.alpha, self.step)/2)+0.5\n","      fixed_fakes=torch.clamp(fixed_fakes,min=0.0,max=1.0)\n","      samples_save=[fixed_fakes]\n","      with open(self.sample_path+'train_samples_'+str(self.step)+'_'+str(self.cur_epoch)+'.pkl', 'wb') as f:\n","        pkl.dump(samples_save, f)\n","  def save_samples(self):\n","    #save training image as .png and.gif\n","    #save only 9 images and one frame per iteration\n","    grid_cells=[]\n","    with torch.no_grad():\n","      fixed_fakes=(self.G(self.fixed_noise1, self.alpha, self.step)/2)+0.5\n","      fixed_fakes=torch.clamp(fixed_fakes,min=0.0,max=1.0)\n","      #upscale all images to 256*256 to make .gif\n","      if fixed_fakes.shape[2]<256:\n","        fixed_fakes=F.interpolate(fixed_fakes,scale_factor=int(256/fixed_fakes.shape[2]))\n","      for i,img in enumerate(fixed_fakes):\n","        if i+1>self.save_only:\n","          break\n","        grid_cells.append(img)\n","        img=np.transpose(img.cpu().numpy(),(1,2,0))\n","        img=(img*255).astype(np.uint8)\n","        plt.imsave(self.sample_path+'train_samples_'+str(self.img_size)+'_'+str(self.cur_epoch)+'_'+str(i)+'.png',img.reshape(256,256),cmap='Greys_r')\n","      #make 3*3 grid image\n","      grid=make_grid(grid_cells,nrow=3).cpu().numpy()\n","      grid=(grid*255).astype(np.uint8)\n","      grid=np.transpose(grid, (1, 2, 0))\n","      frame=Image.fromarray(grid).resize([600,600]).convert('L')\n","      self.gif.append(frame)\n","\n","  def make_gif(self):\n","    #save .gif\n","    self.gif[0].save(self.sample_path+'brain.gif', save_all=True, append_images=self.gif[1:], loop=0, disposal=2,duration=800)\n","  def save_model(self):\n","    #save models for generating new images\n","    save_G={\"state_dict\":self.G.state_dict(),\"optimizer\":self.opt_G.state_dict()}\n","    torch.save(save_G,self.model_path+'G.pth')\n","    save_D={\"state_dict\":self.D.state_dict(),\"optimizer\":self.opt_D.state_dict()}\n","    torch.save(save_D,self.model_path+'D.pth')\n","    \n","  def update_para(self):\n","    #update parameters\n","    self.step+=1\n","    self.img_size=2**(self.step+2)\n","    self.alpha=0.999\n","  def plot_loss(self):\n","    #plot and save losses as .jpg\n","    losses = np.array(self.losses)\n","    plt.plot(losses[0], label='Discriminator', alpha=0.5)\n","    plt.plot(losses[1], label='Generator', alpha=0.5)\n","    plt.title(\"Average Training Losses\")\n","    plt.xlabel(\"per epoch\")\n","    plt.ylabel(\"Non-Saturating loss\")\n","    plt.legend()\n","    plt.savefig(self.sample_path+'loss.jpg')\n","  def training_loop(self):\n","    #all training loops\n","    self.G.train()\n","    self.D.train()\n","    for n_epochs in self.prog_epochs:\n","      print(\"Current img size:\", self.img_size)\n","      self.get_loader()\n","      for epoch in range(n_epochs):\n","        self.cur_epoch=epoch+1\n","        print(\"Epoch: [\",self.cur_epoch,\"/\",n_epochs,\"]\")\n","        self.train_one_epoch()\n","        self.save_samples()\n","\n","      self.update_para()\n","    self.plot_loss()\n","    self.make_gif()\n","    self.save_model()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkvlOpP2ALfa"},"source":["t=Trainer()\n","t.training_loop()"],"execution_count":null,"outputs":[]}]}