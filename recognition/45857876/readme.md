# **Knee MRI Image stylegan**
Student name: Mengyao Ma  
Student number: s4585787  

### Generative Adversarial Network 
![Gan structure](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/gan.png)  
**GAN** is short for **Generative Adversarial Network** proposed by Ian Goodfellow in 2014. The main structure of GAN includes a **Generator(G)** and a **Discriminator (D)**.  For the generator, the input requires an n-dimensional vector, and the output is a picture with the pixel size of the picture, while the discriminator discriminates the pictures generated by the generator and labels them as "fake" or "real".   


### StyleGAN
**StyleGAN** is inspired by **style transfer**  to design a **new generator structure**.  In addtion, StyleGAN is **evolved** from **ProGAN** and uses a similar network structure. StyleGAN uses style to affect the posture and identity characteristics of the face, and noise to affect details such as hair strands, wrinkles, and skin tone. 


## The main StyleGAN structure  
![Traditional genertaor and StyleGAN generator](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/v2-f1db8c75f4efd04e7eef68b56fefc4d3_1440w.jpg)  
Through observation, it can be found that different layers and resolutions will affect different features. The lower the layer and resolution, the coarser the features it affects. We can divide these characteristics into three types:  
1. Rough-(resolution 0-8), affecting posture, general hairstyle, facial shape, etc.; 
2. Medium-(resolution 16-32), affecting finer facial features, hairstyles, opening of eyes or Closed, etc.; 
3. High-quality-(resolution 64-1024), affecting color (eyes, hair and skin) and microscopic features;  


In traditional gan, the generator only feeds the random variables as latent code into input layer.
### Mapping Network

To better solve the Feature unwrapping problem, the Mapping network is added into Generator. It consists of 8 fully connected layers. The Mapping network convert the latent code into 18 vectors after affin transform. These vectors A learned affin transform are added into the synthesis generator network(two for each resolution). The vectors A can control the style on certain resolution.

### AdaIN module

![AdaIN](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/20190325144840976.png)   

At each resolution, two A will affect the generator twice, once after Upsampling and once after Convolution by using AdaIN.
Like the equation ablow, expand A into scaling factors y~ùë†,ùëñ~ and deviation factors y~ùëè,ùëñ~, and make a weighted sum of these two factors and the normalized convolution output to apply an influence.  

### Random nosie

To control the character detail and diversity of image generated, add a scaled noise to each channel before the Adain module. 

### Style mixing

To decrease the correlation, the genarator will randomly choose two vector A, and mix them by mixing factor(in defualt setting, the factor is 0.5). The randomly switch ensure the network will not reply on either correlation between each blocks.    

## **Loss function applied**

In this task, I explore two loss functions to find the influence of loss function.  

### 1.  Logistic loss function
Output for logistic loss function for resolution 256 shows below:  
![resolution 256 epoch9](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/logistic_256gen_6_9_1.png)

### 2. Relativistic Average Hinge loss function
Output for logistic loss function for resolution 256 shows below:  
![resolution 256 epoch9](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/rahingegen_6_9_1.png) 


The two models setting is same except loss function. The result image above is the result of epoch 6 the resolution is 256. Because it is too time consuming, so I just pick the result of epoch 6.  
**However, it is easy to find when the Relativistic Average Hinge loss function is applied, the deformation at the edge of the knee image is more serious. Although, the image generated with Logistic loss fuction also has some strange pixels, it performs better than image with Relativistic Average Hinge loss function.**



## **Output of each resolution**
**The result will present images with Logistic loss function.**
![resolution 4-512](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/output512.jpg) 
![resolution for all precedure](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/resolution256.gif)

From the result we can find, the details will change randomly as the number of layers increases cause the random nosie added in every layer. Compared with the result of resolution 256, knee edges and details of  the preview result 512 are much clearer, and there are no obvious error pixels.

## **Style mixing output**

![test_image](https://github.com/MMMMMYY/PatternFlow/blob/topic-recognition/recognition/45857876/images/figure03-style-mixing.png)  


The test image is generated by generator model (6_32) which is resolution 256 and epoch 32. Because I did not finish training resolution 512, the generator preforms bad on resolution 512.
## Requirments

yacs  
tqdm  
numpy (only for visualization, file test_script.py, generate_mixing_figure.py)  
torchvision  
torch  

## Execute the code
Training:  
    python train.py 
Generate mixing image(test):    
    python generate_mixing_figure.py --generator_file [new256/models/GAN_GEN_4_16.pth](for example)


## The default setting:  

general setting:  
    device = 'cuda'  
    number of preview samples = 36  
    make checkpoint every/epoch = 10  
    test loss:  
        epochs: [2,4,8,8,16,24,32]  
    style mixing:  
        epochs: [2,4,8,8,16,24,32,40]  

Generator setting:  
    latent size = 512  
    mapping layers = 4(8 in original paper, but 4 layers when latene size = 512)  
    blur_filter = [1, 2, 1]   

Discriminator setting:  
    enable equalized learning rate = True  
    blur_filter = [1, 2, 1]  

Generator Optimizer setting:
    optimizer = Adam  
    learning_rate = 0.003  
    betas = [0,0.99]  
    eps = defualt

Discriminator Optimizer setting:
    optimizer = Adam  
    learning_rate = 0.003  
    betas = [0,0.99]  
    eps = defualt
    
    

## Reference
Paper:  
A Style-Based Generator Architecture for Generative Adversarial Networks
Tero Karras (NVIDIA), Samuli Laine (NVIDIA), Timo Aila (NVIDIA)
https://arxiv.org/abs/1812.04948
Progressive Growing of GANs for Improved Quality, Stability, and Variation
Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen
https://arxiv.org/abs/1710.10196
Generative Adversarial Networks
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio
https://arxiv.org/abs/1406.2661

Code:   
https://github.com/huangzh13/StyleGAN.pytorch  
https://github.com/lernapparat/lernapparat
https://github.com/NVlabs/stylegan
https://github.com/akanimax/pro_gan_pytorch
https://github.com/rosinality/style-based-gan-pytorch
https://github.com/goodfeli/adversarial
